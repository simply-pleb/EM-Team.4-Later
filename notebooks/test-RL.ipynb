{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sammon_error(X, selected_features):\n",
    "    \"\"\"\n",
    "    Calculate Sammon error (stress) between original data X and low-dimensional data X_low.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Original data (n_samples, n_features)\n",
    "    - selected_features: Binari vector representing the selected columns (n_features)\n",
    "    \n",
    "    Returns:\n",
    "    - sammon_error: Sammon error (float)\n",
    "    \"\"\"\n",
    "    # Ensure selected_features is a boolean or binary mask\n",
    "    selected_features = np.array(selected_features, dtype=bool)\n",
    "    \n",
    "    X_low = X[:, selected_features]\n",
    "    \n",
    "    # Compute pairwise distances in the original data\n",
    "    D_orig = pdist(X, metric='euclidean')\n",
    "    D_orig = squareform(D_orig)  # Convert to a square matrix\n",
    "    \n",
    "    # Compute pairwise distances in the low-dimensional data (selected features)\n",
    "    D_low = pdist(X_low, metric='euclidean')\n",
    "    D_low = squareform(D_low)\n",
    "    \n",
    "    # Avoid division by zero by replacing zeros with a small number\n",
    "    D_orig[D_orig == 0] = np.finfo(float).eps\n",
    "    \n",
    "    # Calculate the Sammon error (Sammon stress)\n",
    "    delta = D_orig - D_low\n",
    "    sammon_error = np.sum((delta**2) / D_orig)\n",
    "    \n",
    "    # Normalize the error by the sum of original distances\n",
    "    sammon_error /= np.sum(D_orig)\n",
    "    \n",
    "    return sammon_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEUFSEnvironment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_size,\n",
    "        data,\n",
    "        online=True,\n",
    "        sparse=False,\n",
    "        max_features=15,\n",
    "        error_f=sammon_error,\n",
    "    ):\n",
    "        self.state_size = state_size  # Length of the state vector\n",
    "        self.state = np.zeros(\n",
    "            self.state_size, dtype=bool\n",
    "        )  # Initialize state as all False\n",
    "        self.error_f = error_f\n",
    "        self.data = data\n",
    "        self._state_prev_error = None#error_f(data, self.state)\n",
    "        self.online = online\n",
    "        self.cur_num_features = 0\n",
    "        self.max_features = max_features\n",
    "        self.sparse = sparse\n",
    "\n",
    "    def get_done(self):\n",
    "        if self.sparse:\n",
    "            return self.cur_num_features >= self.max_features\n",
    "\n",
    "        return np.all(self.state)\n",
    "\n",
    "    def _get_reward_sparse(self):\n",
    "        self.cur_num_features = int(np.sum(self.state))\n",
    "        r = 0\n",
    "        cur_error = self.error_f(self.data, self.state)\n",
    "        if self._state_prev_error is not None:\n",
    "            dif = self._state_prev_error - cur_error\n",
    "        else:\n",
    "            dif = 1 - cur_error\n",
    "        if self.get_done():\n",
    "            r = 1 - cur_error\n",
    "        # if dif <= 0:\n",
    "        #     dif = -1\n",
    "        r += dif/self.max_features/10\n",
    "            \n",
    "        self._state_prev_error = cur_error\n",
    "        return r\n",
    "\n",
    "    def _get_reward(self, changed_state=True):\n",
    "        if self.online:\n",
    "            cur_error = self.error_f(self.data, self.state)\n",
    "            if self._state_prev_error is not None:\n",
    "                dif = self._state_prev_error - cur_error\n",
    "            else:\n",
    "                dif = -cur_error\n",
    "            self._state_prev_error = cur_error\n",
    "            return dif\n",
    "        if changed_state:\n",
    "            return -self.error_f(self.data, self.state)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def get_reward(self, changed_state=True):\n",
    "        if self.sparse:\n",
    "            return self._get_reward_sparse()\n",
    "        return self._get_reward(changed_state)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the environment state at the start of each episode.\"\"\"\n",
    "        self.state = np.zeros(self.state_size, dtype=bool)\n",
    "        self._state_prev_error = None#error_f(data, self.state)\n",
    "        self.cur_num_features = 0\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Perform the chosen action in the environment.\n",
    "\n",
    "        Args:\n",
    "            action (int): The index in the state to be set to True.\n",
    "\n",
    "        Returns:\n",
    "            state (np.array): Updated state after the action.\n",
    "            reward (float): Reward for taking the action.\n",
    "            done (bool): Whether the episode has ended.\n",
    "            info (dict): Additional info, if any (empty here).\n",
    "        \"\"\"\n",
    "        # Set the state at the action's index to True\n",
    "        prev_state_at = self.state[action]\n",
    "        self.state[action] = True\n",
    "\n",
    "        changed_state = prev_state_at != self.state[action]\n",
    "\n",
    "        # Reward logic\n",
    "        reward = self.get_reward(changed_state)\n",
    "\n",
    "        # Determine if the episode is done (e.g., all states set to True)\n",
    "        done = self.get_done()\n",
    "        # if done:\n",
    "        #     print(done)\n",
    "\n",
    "        return self.state, reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NStepSARSA:\n",
    "    def __init__(self, state_dim, action_dim, n=3, alpha=0.01, gamma=0.99, epsilon=0.1):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.n = n  # Number of steps\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "        \n",
    "        # Initialize Q-table for state-action pairs as zeros\n",
    "        self.q_table = np.zeros((state_dim, action_dim))\n",
    "        print(self.q_table)\n",
    "\n",
    "        # Replay buffer for n-step transitions\n",
    "        self.replay_buffer = []\n",
    "        \n",
    "    def select_action(self, state):\n",
    "        \"\"\"Epsilon-greedy policy for action selection.\"\"\"\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return np.random.choice(self.action_dim)\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state])\n",
    "    \n",
    "    def store_transition(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Store transition in replay buffer.\"\"\"\n",
    "        self.replay_buffer.append((state, action, reward, next_state, done))\n",
    "        \n",
    "        # Remove oldest transition if buffer size exceeds n\n",
    "        if len(self.replay_buffer) > self.n:\n",
    "            self.replay_buffer.pop(0)\n",
    "    \n",
    "    def update_q_values(self):\n",
    "        \"\"\"Perform n-step SARSA update using stored transitions.\"\"\"\n",
    "        if len(self.replay_buffer) < self.n:\n",
    "            return  # Wait until we have enough steps\n",
    "\n",
    "        # Calculate n-step return G using rewards and next state-action pair\n",
    "        G = 0\n",
    "        done = False\n",
    "        for i, (_, _, reward, _, done) in enumerate(self.replay_buffer):\n",
    "            G += (self.gamma ** i) * reward  # Discounted reward sum\n",
    "            if done:\n",
    "                break  # Stop summing rewards if episode has terminated\n",
    "\n",
    "        # Get first state-action pair from the buffer\n",
    "        state, action, _, _, _ = self.replay_buffer[0]\n",
    "        \n",
    "        # If the episode ends within n steps, set next Q-value as zero\n",
    "        if done:\n",
    "            td_target = G\n",
    "        else:\n",
    "            # If episode continues, include next Q-value estimate\n",
    "            next_state, next_action, _, _, _ = self.replay_buffer[-1]\n",
    "            td_target = G + (self.gamma ** self.n) * self.q_table[next_state][next_action]\n",
    "        \n",
    "        # SARSA Update: Q(S, A) <- Q(S, A) + alpha * (td_target - Q(S, A))\n",
    "        td_error = td_target - self.q_table[state][action]\n",
    "        self.q_table[state][action] += self.alpha * td_error\n",
    "        \n",
    "    def train(self, env: SEUFSEnvironment, episodes: int, max_steps: int):\n",
    "        \"\"\"Train the agent using n-step SARSA.\"\"\"\n",
    "        for episode in range(episodes):\n",
    "            state = env.reset()  # Reset the environment to the starting state\n",
    "            action = self.select_action(state)\n",
    "            self.replay_buffer = []  # Clear the replay buffer for each episode\n",
    "            \n",
    "            for step in range(max_steps):\n",
    "                # Take action, observe reward and next state\n",
    "                next_state, reward, done, _ = env.step(action)  # Assuming env.step returns (next_state, reward, done, info)\n",
    "                next_action = self.select_action(next_state)\n",
    "                \n",
    "                # Store transition and update Q-values if enough steps are taken\n",
    "                self.store_transition(state, action, reward, next_state, done)\n",
    "                self.update_q_values()\n",
    "                \n",
    "                # Move to the next state and action\n",
    "                state, action = next_state, next_action\n",
    "                \n",
    "                # Break if episode is done\n",
    "                if done:\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repository</th>\n",
       "      <th>LCOM5</th>\n",
       "      <th>WMC</th>\n",
       "      <th>CBO</th>\n",
       "      <th>NOI_c</th>\n",
       "      <th>RFC</th>\n",
       "      <th>CLOC_c</th>\n",
       "      <th>DIT</th>\n",
       "      <th>NOA</th>\n",
       "      <th>NOC</th>\n",
       "      <th>...</th>\n",
       "      <th>TNOS_m</th>\n",
       "      <th>HCPL</th>\n",
       "      <th>HDIF</th>\n",
       "      <th>HEFF</th>\n",
       "      <th>HNDB</th>\n",
       "      <th>HPL</th>\n",
       "      <th>HPV</th>\n",
       "      <th>HTRP</th>\n",
       "      <th>HVOL</th>\n",
       "      <th>MI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recommenders-team_recommenders</td>\n",
       "      <td>3.484536</td>\n",
       "      <td>13.948454</td>\n",
       "      <td>0.268041</td>\n",
       "      <td>0.175258</td>\n",
       "      <td>5.865979</td>\n",
       "      <td>47.845361</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>...</td>\n",
       "      <td>10.424908</td>\n",
       "      <td>17.626091</td>\n",
       "      <td>0.946289</td>\n",
       "      <td>123.713377</td>\n",
       "      <td>0.011553</td>\n",
       "      <td>8.822311</td>\n",
       "      <td>5.909960</td>\n",
       "      <td>6.872965</td>\n",
       "      <td>34.659469</td>\n",
       "      <td>52.708286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ansible_ansible</td>\n",
       "      <td>2.460000</td>\n",
       "      <td>11.521935</td>\n",
       "      <td>0.383871</td>\n",
       "      <td>0.249032</td>\n",
       "      <td>3.944516</td>\n",
       "      <td>9.249677</td>\n",
       "      <td>0.267097</td>\n",
       "      <td>0.274839</td>\n",
       "      <td>0.223871</td>\n",
       "      <td>...</td>\n",
       "      <td>8.096763</td>\n",
       "      <td>16.960101</td>\n",
       "      <td>0.821704</td>\n",
       "      <td>140.214293</td>\n",
       "      <td>0.010462</td>\n",
       "      <td>7.453463</td>\n",
       "      <td>5.358586</td>\n",
       "      <td>7.789683</td>\n",
       "      <td>31.384585</td>\n",
       "      <td>43.619663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>python_mypy</td>\n",
       "      <td>4.745626</td>\n",
       "      <td>20.709287</td>\n",
       "      <td>0.522207</td>\n",
       "      <td>0.554509</td>\n",
       "      <td>8.247645</td>\n",
       "      <td>17.150740</td>\n",
       "      <td>0.803499</td>\n",
       "      <td>0.816958</td>\n",
       "      <td>0.366083</td>\n",
       "      <td>...</td>\n",
       "      <td>5.554887</td>\n",
       "      <td>15.700527</td>\n",
       "      <td>0.851261</td>\n",
       "      <td>123.168731</td>\n",
       "      <td>0.009638</td>\n",
       "      <td>7.055235</td>\n",
       "      <td>5.086295</td>\n",
       "      <td>6.842707</td>\n",
       "      <td>28.915393</td>\n",
       "      <td>25.116836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpcaitech_ColossalAI</td>\n",
       "      <td>3.167149</td>\n",
       "      <td>10.542692</td>\n",
       "      <td>0.329233</td>\n",
       "      <td>0.335745</td>\n",
       "      <td>4.484805</td>\n",
       "      <td>15.290883</td>\n",
       "      <td>0.156295</td>\n",
       "      <td>0.156295</td>\n",
       "      <td>0.138205</td>\n",
       "      <td>...</td>\n",
       "      <td>7.389521</td>\n",
       "      <td>19.964883</td>\n",
       "      <td>1.040007</td>\n",
       "      <td>203.418684</td>\n",
       "      <td>0.014098</td>\n",
       "      <td>9.626516</td>\n",
       "      <td>5.939346</td>\n",
       "      <td>11.301038</td>\n",
       "      <td>42.294285</td>\n",
       "      <td>53.518406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>httpie_cli</td>\n",
       "      <td>2.305389</td>\n",
       "      <td>5.107784</td>\n",
       "      <td>0.365269</td>\n",
       "      <td>0.221557</td>\n",
       "      <td>3.113772</td>\n",
       "      <td>4.874251</td>\n",
       "      <td>0.257485</td>\n",
       "      <td>0.263473</td>\n",
       "      <td>0.239521</td>\n",
       "      <td>...</td>\n",
       "      <td>4.327044</td>\n",
       "      <td>10.140832</td>\n",
       "      <td>0.789708</td>\n",
       "      <td>36.672611</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>5.623834</td>\n",
       "      <td>4.638342</td>\n",
       "      <td>2.037367</td>\n",
       "      <td>17.734353</td>\n",
       "      <td>49.713385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       repository     LCOM5        WMC       CBO     NOI_c  \\\n",
       "0  recommenders-team_recommenders  3.484536  13.948454  0.268041  0.175258   \n",
       "1                 ansible_ansible  2.460000  11.521935  0.383871  0.249032   \n",
       "2                     python_mypy  4.745626  20.709287  0.522207  0.554509   \n",
       "3            hpcaitech_ColossalAI  3.167149  10.542692  0.329233  0.335745   \n",
       "4                      httpie_cli  2.305389   5.107784  0.365269  0.221557   \n",
       "\n",
       "        RFC     CLOC_c       DIT       NOA       NOC  ...     TNOS_m  \\\n",
       "0  5.865979  47.845361  0.030928  0.030928  0.030928  ...  10.424908   \n",
       "1  3.944516   9.249677  0.267097  0.274839  0.223871  ...   8.096763   \n",
       "2  8.247645  17.150740  0.803499  0.816958  0.366083  ...   5.554887   \n",
       "3  4.484805  15.290883  0.156295  0.156295  0.138205  ...   7.389521   \n",
       "4  3.113772   4.874251  0.257485  0.263473  0.239521  ...   4.327044   \n",
       "\n",
       "        HCPL      HDIF        HEFF      HNDB       HPL       HPV       HTRP  \\\n",
       "0  17.626091  0.946289  123.713377  0.011553  8.822311  5.909960   6.872965   \n",
       "1  16.960101  0.821704  140.214293  0.010462  7.453463  5.358586   7.789683   \n",
       "2  15.700527  0.851261  123.168731  0.009638  7.055235  5.086295   6.842707   \n",
       "3  19.964883  1.040007  203.418684  0.014098  9.626516  5.939346  11.301038   \n",
       "4  10.140832  0.789708   36.672611  0.005911  5.623834  4.638342   2.037367   \n",
       "\n",
       "        HVOL         MI  \n",
       "0  34.659469  52.708286  \n",
       "1  31.384585  43.619663  \n",
       "2  28.915393  25.116836  \n",
       "3  42.294285  53.518406  \n",
       "4  17.734353  49.713385  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"../data/data_train.csv\", sep=',')\n",
    "data_test = pd.read_csv(\"../data/data_test.csv\", sep=',')\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 3.48453608, 13.94845361,  0.26804124, ...,  6.87296538,\n",
       "         34.65946915, 52.70828605],\n",
       "        [ 2.46      , 11.52193548,  0.38387097, ...,  7.78968294,\n",
       "         31.38458498, 43.61966283],\n",
       "        [ 4.74562584, 20.70928668,  0.52220727, ...,  6.84270728,\n",
       "         28.91539346, 25.11683622],\n",
       "        ...,\n",
       "        [ 1.53791187,  8.14767765,  0.39976181, ..., 10.55182418,\n",
       "         41.75895437, 35.24916235],\n",
       "        [ 3.91798561, 16.0057554 ,  0.63021583, ...,  6.18104476,\n",
       "         24.76377797, 68.96475529],\n",
       "        [ 4.25903614, 12.1686747 ,  0.57228916, ...,  8.3908338 ,\n",
       "         44.03298782, 39.82271873]]),\n",
       " (84, 42))"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data_train.drop(columns=[\"repository\"], inplace=False)\n",
    "X_train = X_train.to_numpy()\n",
    "X_train, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2.63470874e+00, 1.10558252e+01, 1.72330097e-01, 1.37135922e-01,\n",
       "         4.39077670e+00, 1.19490291e+01, 1.16504854e-01, 1.16504854e-01,\n",
       "         1.09223301e-01, 1.16504854e-01, 1.09223301e-01, 8.04623786e+01,\n",
       "         6.47111650e+01, 4.48179612e+00, 4.25364078e+00, 3.17439320e+01,\n",
       "         8.05546117e+01, 6.47864078e+01, 4.56067961e+00, 4.26213592e+00,\n",
       "         3.17657767e+01, 2.64287786e+00, 4.64461851e-01, 2.40847113e+00,\n",
       "         1.75398898e+00, 2.43051929e+00, 1.27249782e+01, 1.67977952e+01,\n",
       "         7.46330142e+00, 1.94313896e+00, 1.29019437e+01, 1.70092834e+01,\n",
       "         7.58862779e+00, 1.06088154e+01, 6.67731208e-01, 6.62787645e+01,\n",
       "         6.68143130e-03, 5.55038968e+00, 4.09916689e+00, 3.68215358e+00,\n",
       "         2.00442939e+01, 5.49371907e+01],\n",
       "        [2.06217617e+00, 6.85967185e+00, 4.16234888e-01, 3.60967185e-01,\n",
       "         3.17487047e+00, 1.09611399e+01, 3.68739206e-01, 3.80397237e-01,\n",
       "         3.02677029e-01, 3.80397237e-01, 3.02677029e-01, 5.41809154e+01,\n",
       "         4.49313472e+01, 5.02633851e+00, 2.81390328e+00, 1.99378238e+01,\n",
       "         5.41951641e+01, 4.49399827e+01, 5.06519862e+00, 2.81735751e+00,\n",
       "         1.99447323e+01, 2.46884227e+00, 4.24864025e-01, 3.01134421e+00,\n",
       "         2.17622378e+00, 3.02222222e+00, 1.31508936e+01, 1.68362082e+01,\n",
       "         7.11080031e+00, 2.18041958e+00, 1.32627817e+01, 1.69591298e+01,\n",
       "         7.17762238e+00, 1.43719254e+01, 8.16929649e-01, 1.11942266e+02,\n",
       "         9.06088872e-03, 6.80588138e+00, 4.83049727e+00, 6.21901476e+00,\n",
       "         2.71826662e+01, 4.96412283e+01],\n",
       "        [3.59577836e+00, 7.75567282e+00, 2.39577836e-01, 2.24274406e-01,\n",
       "         4.67704485e+00, 7.22480211e+00, 1.11345646e-01, 1.15039578e-01,\n",
       "         9.92084433e-02, 1.15039578e-01, 9.92084433e-02, 7.56907652e+01,\n",
       "         6.16406332e+01, 4.74511873e+00, 4.45277045e+00, 2.67187335e+01,\n",
       "         7.82411609e+01, 6.34944591e+01, 5.68073879e+00, 5.08918206e+00,\n",
       "         2.77577836e+01, 1.86723415e+00, 2.39105577e-01, 1.43145725e+00,\n",
       "         6.37657223e-01, 1.46334646e+00, 1.27367552e+01, 1.52975480e+01,\n",
       "         6.14343794e+00, 2.58810825e+00, 1.33905476e+01, 1.60030492e+01,\n",
       "         6.43869902e+00, 6.83957026e+00, 4.28989209e-01, 2.96993792e+01,\n",
       "         4.12552784e-03, 3.61810829e+00, 2.76526907e+00, 1.64996551e+00,\n",
       "         1.23765835e+01, 4.95056309e+01],\n",
       "        [2.64531680e+00, 7.17906336e+00, 4.64876033e-01, 2.05234160e-01,\n",
       "         3.47382920e+00, 1.16060606e+01, 1.75619835e-01, 1.79752066e-01,\n",
       "         1.45316804e-01, 1.79752066e-01, 1.45316804e-01, 4.66019284e+01,\n",
       "         3.51811295e+01, 4.39669421e+00, 3.26859504e+00, 1.91639118e+01,\n",
       "         4.66184573e+01, 3.51976584e+01, 4.61639118e+00, 3.41735537e+00,\n",
       "         1.96246556e+01, 2.24510015e+00, 2.56945940e-01, 2.09002800e+00,\n",
       "         1.44690933e+00, 2.14344174e+00, 8.34998923e+00, 1.09588628e+01,\n",
       "         5.82166703e+00, 2.37669610e+00, 8.80292914e+00, 1.14766315e+01,\n",
       "         6.13719578e+00, 1.65092209e+01, 9.87596232e-01, 1.25473137e+02,\n",
       "         1.05517468e-02, 8.05730819e+00, 5.60369610e+00, 6.97072982e+00,\n",
       "         3.16552405e+01, 4.72980591e+01],\n",
       "        [2.26190476e+00, 7.88095238e+00, 2.97619048e-01, 2.73809524e-01,\n",
       "         3.26785714e+00, 1.08988095e+01, 2.38095238e-02, 2.38095238e-02,\n",
       "         2.38095238e-02, 2.38095238e-02, 2.38095238e-02, 6.01130952e+01,\n",
       "         4.74285714e+01, 3.05952381e+00, 2.99404762e+00, 2.87142857e+01,\n",
       "         6.01130952e+01, 4.74285714e+01, 3.05952381e+00, 2.99404762e+00,\n",
       "         2.87142857e+01, 2.63220676e+00, 3.95626243e-01, 2.88667992e+00,\n",
       "         1.54473161e+00, 2.88667992e+00, 1.35705765e+01, 1.77097416e+01,\n",
       "         9.59045726e+00, 3.34791252e+00, 1.35705765e+01, 1.77097416e+01,\n",
       "         9.59045726e+00, 2.51060244e+01, 1.41143673e+00, 2.80354571e+02,\n",
       "         1.72253837e-02, 1.18326180e+01, 7.62804006e+00, 1.55752539e+01,\n",
       "         5.16761512e+01, 5.21362483e+01],\n",
       "        [2.69395712e+00, 8.96393762e+00, 3.37231969e-01, 4.24951267e-01,\n",
       "         3.89863548e+00, 1.81890838e+01, 1.03313840e-01, 1.07212476e-01,\n",
       "         9.94152047e-02, 1.07212476e-01, 9.94152047e-02, 7.29385965e+01,\n",
       "         5.69191033e+01, 3.85380117e+00, 3.47368421e+00, 2.81676413e+01,\n",
       "         7.29814815e+01, 5.69600390e+01, 3.97173489e+00, 3.47855750e+00,\n",
       "         2.81832359e+01, 2.66734339e+00, 3.47157773e-01, 3.54756381e+00,\n",
       "         2.64124130e+00, 3.58613689e+00, 1.32552204e+01, 1.78071346e+01,\n",
       "         8.03683295e+00, 3.15574246e+00, 1.37302784e+01, 1.83677494e+01,\n",
       "         8.38283063e+00, 2.22279191e+01, 1.21252611e+00, 2.31571812e+02,\n",
       "         1.46183899e-02, 1.01920787e+01, 6.79290707e+00, 1.28651007e+01,\n",
       "         4.38551698e+01, 5.28635117e+01],\n",
       "        [2.73024055e+00, 7.91065292e+00, 2.98969072e-01, 3.79725086e-01,\n",
       "         3.96391753e+00, 1.86408935e+01, 1.44329897e-01, 1.44329897e-01,\n",
       "         1.16838488e-01, 1.44329897e-01, 1.16838488e-01, 7.23333333e+01,\n",
       "         5.87800687e+01, 3.94329897e+00, 3.58419244e+00, 2.74707904e+01,\n",
       "         7.24226804e+01, 5.88453608e+01, 4.14604811e+00, 3.65979381e+00,\n",
       "         2.76237113e+01, 2.28827038e+00, 3.38469185e-01, 4.17544732e+00,\n",
       "         3.14960239e+00, 4.20178926e+00, 1.29448310e+01, 1.78250497e+01,\n",
       "         7.74652087e+00, 2.56212724e+00, 1.33006958e+01, 1.82162028e+01,\n",
       "         7.97912525e+00, 1.89324299e+01, 1.08003721e+00, 1.60864640e+02,\n",
       "         1.22861356e-02, 8.95806746e+00, 6.10619872e+00, 8.93692446e+00,\n",
       "         3.68584067e+01, 5.49571779e+01],\n",
       "        [3.74489796e+00, 1.62959184e+01, 2.34693878e-01, 6.73469388e-01,\n",
       "         5.42857143e+00, 1.01938776e+01, 1.12244898e-01, 1.12244898e-01,\n",
       "         7.14285714e-02, 1.12244898e-01, 7.14285714e-02, 7.31632653e+01,\n",
       "         6.51428571e+01, 5.71428571e+00, 4.75510204e+00, 4.39387755e+01,\n",
       "         7.31632653e+01, 6.51428571e+01, 5.80612245e+00, 4.75510204e+00,\n",
       "         4.39387755e+01, 3.49452954e+00, 4.11378556e-01, 2.01531729e+00,\n",
       "         1.20568928e+00, 2.02407002e+00, 1.20196937e+01, 1.41859956e+01,\n",
       "         9.32166302e+00, 2.24726477e+00, 1.21575492e+01, 1.43326039e+01,\n",
       "         9.42231947e+00, 2.32690622e+01, 1.03837272e+00, 1.53928582e+02,\n",
       "         1.39255028e-02, 9.70957096e+00, 6.90429043e+00, 8.55158792e+00,\n",
       "         4.17765084e+01, 5.19295769e+01],\n",
       "        [3.72585309e+00, 7.54308849e+00, 4.48814344e-01, 5.05494505e-01,\n",
       "         4.93753615e+00, 1.11041064e+01, 3.38345865e-01, 3.75361481e-01,\n",
       "         2.71255061e-01, 3.75361481e-01, 2.71255061e-01, 6.23157895e+01,\n",
       "         4.82492770e+01, 7.20011567e+00, 4.43204164e+00, 2.95211105e+01,\n",
       "         6.23325622e+01, 4.82643146e+01, 7.43666859e+00, 4.53441296e+00,\n",
       "         2.97038751e+01, 1.75508007e+00, 3.14224196e-01, 1.92490916e+00,\n",
       "         9.13066882e-01, 1.96487687e+00, 9.39806217e+00, 1.20004037e+01,\n",
       "         6.77459292e+00, 1.52011842e+00, 9.65401696e+00, 1.22862333e+01,\n",
       "         6.91024088e+00, 1.48465678e+01, 9.47962093e-01, 1.70625298e+02,\n",
       "         1.09471385e-02, 8.21838642e+00, 4.95832539e+00, 9.47918320e+00,\n",
       "         3.28414155e+01, 1.99826836e+01],\n",
       "        [1.41715976e+00, 4.10059172e+00, 2.57396450e-01, 1.44970414e-01,\n",
       "         1.81360947e+00, 2.68047337e+00, 1.89349112e-01, 1.89349112e-01,\n",
       "         1.77514793e-01, 1.89349112e-01, 1.77514793e-01, 2.91094675e+01,\n",
       "         2.34733728e+01, 1.87278107e+00, 1.66863905e+00, 1.02573964e+01,\n",
       "         2.94763314e+01, 2.37692308e+01, 1.93786982e+00, 1.71597633e+00,\n",
       "         1.04881657e+01, 2.48387097e+00, 2.41935484e-01, 1.10931900e+00,\n",
       "         4.44444444e-01, 1.12186380e+00, 1.03154122e+01, 1.23906810e+01,\n",
       "         6.16666667e+00, 2.49283154e+00, 1.04301075e+01, 1.25430108e+01,\n",
       "         6.25627240e+00, 1.54985446e+01, 9.21931031e-01, 1.35309465e+02,\n",
       "         1.01107344e-02, 7.46505190e+00, 5.09896194e+00, 7.51719248e+00,\n",
       "         3.03322032e+01, 5.06217035e+01],\n",
       "        [2.70998117e+00, 1.48192090e+01, 3.89830508e-01, 3.16384181e-01,\n",
       "         4.00753296e+00, 8.89453861e+00, 3.40866290e-01, 3.65348399e-01,\n",
       "         2.37288136e-01, 3.65348399e-01, 2.37288136e-01, 6.26233522e+01,\n",
       "         4.70941620e+01, 7.70244821e+00, 3.69114878e+00, 3.34538606e+01,\n",
       "         6.27966102e+01, 4.72354049e+01, 7.80414313e+00, 3.71563089e+00,\n",
       "         3.35273070e+01, 4.10057322e+00, 3.86659719e-01, 1.61959354e+00,\n",
       "         9.46326212e-01, 1.62636790e+00, 1.11646691e+01, 1.46925482e+01,\n",
       "         9.18342887e+00, 2.01459093e+00, 1.12772277e+01, 1.48150078e+01,\n",
       "         9.26003127e+00, 4.69418329e+01, 1.33166655e+00, 7.61209900e+02,\n",
       "         3.21101217e-02, 1.72441140e+01, 1.04060306e+01, 4.22894389e+01,\n",
       "         9.63303650e+01, 4.01522868e+01],\n",
       "        [4.39012346e+00, 1.48765432e+01, 4.04938272e-01, 2.44444444e-01,\n",
       "         5.95555556e+00, 1.36716049e+01, 2.19753086e-01, 2.37037037e-01,\n",
       "         1.85185185e-01, 2.37037037e-01, 1.85185185e-01, 7.85925926e+01,\n",
       "         6.72197531e+01, 6.97283951e+00, 5.71111111e+00, 3.80469136e+01,\n",
       "         7.85925926e+01, 6.72197531e+01, 7.09382716e+00, 5.71111111e+00,\n",
       "         3.80469136e+01, 2.66121908e+00, 2.93727915e-01, 2.14796820e+00,\n",
       "         1.61837456e+00, 2.16607774e+00, 1.00013251e+01, 1.23719081e+01,\n",
       "         6.68242049e+00, 3.92314488e+00, 1.01594523e+01, 1.25587456e+01,\n",
       "         6.80609541e+00, 1.61683421e+01, 9.25846801e-01, 2.05357916e+02,\n",
       "         1.15242683e-02, 7.92525253e+00, 5.01777778e+00, 1.14087731e+01,\n",
       "         3.45728049e+01, 4.64631814e+01],\n",
       "        [3.20000000e+00, 8.13571429e+00, 5.78571429e-01, 4.35714286e-01,\n",
       "         4.49642857e+00, 3.52142857e+00, 2.85714286e-01, 2.85714286e-01,\n",
       "         2.46428571e-01, 2.85714286e-01, 2.46428571e-01, 3.07464286e+01,\n",
       "         2.59035714e+01, 6.46071429e+00, 4.06071429e+00, 1.77928571e+01,\n",
       "         3.07714286e+01, 2.59250000e+01, 6.50714286e+00, 4.08214286e+00,\n",
       "         1.78178571e+01, 2.01592920e+00, 3.43362832e-01, 6.23893805e-01,\n",
       "         4.51327434e-01, 6.23893805e-01, 5.49911504e+00, 6.17964602e+00,\n",
       "         4.38141593e+00, 3.07876106e+00, 5.53185841e+00, 6.21238938e+00,\n",
       "         4.41150442e+00, 1.09639476e+01, 8.09063990e-01, 7.26423027e+01,\n",
       "         7.02359140e-03, 5.84825493e+00, 4.21320182e+00, 4.03568348e+00,\n",
       "         2.10707742e+01, 2.81085606e+01],\n",
       "        [2.61991870e+00, 7.11382114e+00, 4.10569106e-01, 2.22560976e-01,\n",
       "         3.64939024e+00, 4.32418699e+00, 2.69308943e-01, 2.69308943e-01,\n",
       "         1.94105691e-01, 2.69308943e-01, 1.94105691e-01, 4.41605691e+01,\n",
       "         3.70050813e+01, 4.17276423e+00, 3.42682927e+00, 1.86798780e+01,\n",
       "         4.78323171e+01, 4.02286585e+01, 4.43902439e+00, 3.64532520e+00,\n",
       "         1.98363821e+01, 2.10526316e+00, 3.58496241e-01, 8.68872180e-01,\n",
       "         4.81503759e-01, 8.71278195e-01, 9.20631579e+00, 1.04640602e+01,\n",
       "         5.45744361e+00, 1.95368421e+00, 9.32481203e+00, 1.05852632e+01,\n",
       "         5.53203008e+00, 1.56634285e+01, 7.05696151e-01, 7.03163287e+01,\n",
       "         9.70240288e-03, 7.40579710e+00, 5.17418143e+00, 3.90646270e+00,\n",
       "         2.91072086e+01, 4.13015494e+01],\n",
       "        [2.11604788e+00, 4.09078921e+00, 3.57780483e-01, 1.07932644e-01,\n",
       "         2.72702374e+00, 4.37096774e+00, 2.04605397e-01, 2.23473321e-01,\n",
       "         1.64637858e-01, 2.23473321e-01, 1.64637858e-01, 3.82467032e+01,\n",
       "         3.23208562e+01, 3.77926557e+00, 2.61909109e+00, 1.27242848e+01,\n",
       "         3.85869345e+01, 3.26586529e+01, 3.89440049e+00, 2.66200041e+00,\n",
       "         1.27930615e+01, 1.60620544e+00, 2.56502171e-01, 1.46620464e+00,\n",
       "         7.92408492e-01, 1.49316924e+00, 1.01508743e+01, 1.20295933e+01,\n",
       "         4.93161270e+00, 1.49324889e+00, 1.05985980e+01, 1.25087824e+01,\n",
       "         5.02162743e+00, 4.06334520e+00, 2.96069596e-01, 2.30730383e+01,\n",
       "         2.51993629e-03, 2.22945481e+00, 1.71479931e+00, 1.28183546e+00,\n",
       "         7.55980886e+00, 4.32777732e+01],\n",
       "        [2.34368071e+00, 6.89135255e+00, 5.12195122e-01, 4.45676275e-01,\n",
       "         3.18181818e+00, 6.90243902e+00, 8.86917960e-02, 8.86917960e-02,\n",
       "         7.31707317e-02, 8.86917960e-02, 7.31707317e-02, 5.49246120e+01,\n",
       "         4.44257206e+01, 3.17738359e+00, 2.73614191e+00, 2.37871397e+01,\n",
       "         5.50465632e+01, 4.45388027e+01, 3.25055432e+00, 2.74501109e+00,\n",
       "         2.38514412e+01, 2.57925311e+00, 3.29460581e-01, 1.60000000e+00,\n",
       "         6.60580913e-01, 1.61078838e+00, 1.48755187e+01, 1.75369295e+01,\n",
       "         8.65394191e+00, 3.61576763e+00, 1.51950207e+01, 1.79120332e+01,\n",
       "         8.90290456e+00, 4.04175221e+01, 1.68331241e+00, 5.34420323e+02,\n",
       "         2.95304213e-02, 1.80042373e+01, 1.02997881e+01, 2.96900180e+01,\n",
       "         8.85912639e+01, 3.24807729e+01],\n",
       "        [2.97161836e+00, 1.18315217e+01, 5.99637681e-01, 3.48429952e-01,\n",
       "         4.42270531e+00, 1.49094203e+01, 6.07487923e-01, 6.15338164e-01,\n",
       "         4.19082126e-01, 6.15338164e-01, 4.19082126e-01, 6.46884058e+01,\n",
       "         5.03140097e+01, 9.10567633e+00, 4.07427536e+00, 2.50404589e+01,\n",
       "         6.48677536e+01, 5.04528986e+01, 9.21135266e+00, 4.08937198e+00,\n",
       "         2.51032609e+01, 2.96998636e+00, 3.98817644e-01, 2.67091102e+00,\n",
       "         1.62922541e+00, 2.69455813e+00, 9.97832348e+00, 1.31561316e+01,\n",
       "         6.17507958e+00, 2.27012278e+00, 1.01593148e+01, 1.33642565e+01,\n",
       "         6.29028346e+00, 1.36376662e+01, 8.81375690e-01, 1.05298424e+02,\n",
       "         8.71331358e-03, 6.76901443e+00, 4.83944730e+00, 5.84991244e+00,\n",
       "         2.61399407e+01, 3.57943410e+01],\n",
       "        [3.99661400e+00, 1.39808126e+01, 6.80586907e-01, 6.38826185e-01,\n",
       "         6.33521445e+00, 4.04074492e+01, 5.42889391e-01, 5.72234763e-01,\n",
       "         3.45372460e-01, 5.72234763e-01, 3.45372460e-01, 1.04386005e+02,\n",
       "         8.32020316e+01, 1.44458239e+01, 5.69638826e+00, 3.55011287e+01,\n",
       "         1.06364560e+02, 8.46851016e+01, 1.46512415e+01, 5.80812641e+00,\n",
       "         3.61083521e+01, 2.49536664e+00, 4.74415794e-01, 6.04411765e+00,\n",
       "         4.97703465e+00, 6.08541499e+00, 9.12228042e+00, 1.57209911e+01,\n",
       "         6.22502015e+00, 2.43170830e+00, 9.28867849e+00, 1.59339243e+01,\n",
       "         6.33722804e+00, 1.73936138e+01, 9.77563947e-01, 1.86802713e+02,\n",
       "         1.22313626e-02, 8.86492212e+00, 5.59775701e+00, 1.03779285e+01,\n",
       "         3.66940877e+01, 2.33502377e+01],\n",
       "        [7.77715877e+00, 1.44930362e+01, 2.45125348e-01, 1.64345404e-01,\n",
       "         9.69637883e+00, 1.51693593e+02, 3.89972145e-01, 3.89972145e-01,\n",
       "         2.03342618e-01, 3.89972145e-01, 2.03342618e-01, 2.70805014e+02,\n",
       "         2.58944290e+02, 1.05793872e+01, 9.53203343e+00, 2.35738162e+01,\n",
       "         2.70805014e+02, 2.58944290e+02, 1.06713092e+01, 9.53203343e+00,\n",
       "         2.35738162e+01, 1.53526114e+00, 2.00059014e-01, 1.60177043e+01,\n",
       "         1.58397757e+01, 1.60274417e+01, 1.12165831e+01, 2.72735320e+01,\n",
       "         2.45205075e+00, 3.94541163e+00, 1.12959575e+01, 2.73623488e+01,\n",
       "         2.49719681e+00, 9.45458171e+00, 5.92973226e-01, 9.36798471e+01,\n",
       "         6.44394684e-03, 4.71826554e+00, 3.09854183e+00, 5.20443595e+00,\n",
       "         1.93318405e+01, 4.17879453e+01],\n",
       "        [2.32558140e+00, 8.27906977e+00, 1.86046512e-01, 2.79069767e-01,\n",
       "         3.19767442e+00, 1.38604651e+01, 5.81395349e-02, 5.81395349e-02,\n",
       "         4.65116279e-02, 5.81395349e-02, 4.65116279e-02, 5.07441860e+01,\n",
       "         4.40116279e+01, 2.86046512e+00, 2.91860465e+00, 1.81511628e+01,\n",
       "         5.12906977e+01, 4.44534884e+01, 3.09302326e+00, 3.03488372e+00,\n",
       "         1.88720930e+01, 2.95435685e+00, 3.52697095e-01, 4.81327801e+00,\n",
       "         4.49377593e+00, 4.81327801e+00, 9.70539419e+00, 1.56348548e+01,\n",
       "         6.36514523e+00, 2.24066390e+00, 1.00663900e+01, 1.60705394e+01,\n",
       "         6.62240664e+00, 9.12844698e+00, 6.67385566e-01, 6.13672896e+01,\n",
       "         5.83382568e-03, 5.29757463e+00, 4.13432836e+00, 3.40929386e+00,\n",
       "         1.75014770e+01, 3.92937692e+01],\n",
       "        [2.42245073e+00, 4.82433590e+00, 6.28106255e-01, 1.95372751e-01,\n",
       "         3.54670094e+00, 2.91345330e+00, 3.65895458e-01, 3.94173093e-01,\n",
       "         2.84490146e-01, 3.94173093e-01, 2.84490146e-01, 4.03221937e+01,\n",
       "         3.39597258e+01, 5.08826050e+00, 3.35132819e+00, 1.55724079e+01,\n",
       "         4.09691517e+01, 3.45509854e+01, 5.34447301e+00, 3.46529563e+00,\n",
       "         1.58466153e+01, 1.50333778e+00, 3.73564753e-01, 6.16288385e-01,\n",
       "         3.21762350e-01, 6.29105474e-01, 8.90947931e+00, 1.00024032e+01,\n",
       "         4.71615487e+00, 1.76822430e+00, 9.31428571e+00, 1.04416555e+01,\n",
       "         4.89719626e+00, 2.90472172e+00, 2.75639999e-01, 9.66427193e+00,\n",
       "         1.82750654e-03, 1.94018534e+00, 1.55827015e+00, 5.36903996e-01,\n",
       "         5.48251962e+00, 4.56901757e+01],\n",
       "        [9.47261663e-01, 2.78498986e+00, 2.06896552e-01, 6.49087221e-02,\n",
       "         1.34685598e+00, 1.18722110e+01, 1.48073022e-01, 1.48073022e-01,\n",
       "         1.44016227e-01, 1.48073022e-01, 1.44016227e-01, 3.21987830e+01,\n",
       "         2.24259635e+01, 1.94320487e+00, 1.28194726e+00, 4.94523327e+00,\n",
       "         3.22981744e+01, 2.24807302e+01, 1.97160243e+00, 1.28194726e+00,\n",
       "         4.94523327e+00, 2.22168285e+00, 2.28155340e-01, 6.25242718e+00,\n",
       "         5.49676375e+00, 6.27993528e+00, 8.10194175e+00, 1.48462783e+01,\n",
       "         3.89482201e+00, 1.84304207e+00, 8.21035599e+00, 1.49886731e+01,\n",
       "         3.94498382e+00, 8.30329636e+00, 6.70145816e-01, 2.27562543e+02,\n",
       "         5.72310291e-03, 5.07461407e+00, 3.58319039e+00, 1.26423635e+01,\n",
       "         1.71693087e+01, 5.09926272e+01]]),\n",
       " (22, 42))"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = data_test.drop(columns=[\"repository\"], inplace=False)\n",
    "X_test = X_test.to_numpy()\n",
    "X_test, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 42)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_space = X_train.shape[1]\n",
    "action_space = X_train.shape[1]\n",
    "\n",
    "state_space, action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prev error None\n",
      "Initial State: [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n",
      "Action taken: 0, New State: [ True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False], Reward: -0.9854289273140168, Done: False\n",
      "Action taken: 2, New State: [ True False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False], Reward: 0.0005064187704258982, Done: False\n",
      "Action taken: 4, New State: [ True False  True False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False], Reward: 0.011873178971756104, Done: False\n",
      "Action taken: 1, New State: [ True  True  True False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False], Reward: 0.03838290232200958, Done: False\n",
      "Action taken: 3, New State: [ True  True  True  True  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False], Reward: 0.00012198609675007077, Done: False\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "env = SEUFSEnvironment(state_size=state_space, data=X_train)\n",
    "\n",
    "state = env.reset()\n",
    "print(\"Initial prev error\", env._state_prev_error)\n",
    "print(\"Initial State:\", state)\n",
    "\n",
    "actions = [0, 2, 4, 1, 3]  # Sequence of actions to take\n",
    "\n",
    "for action in actions:\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    print(f\"Action taken: {action}, New State: {state}, Reward: {reward}, Done: {done}\")\n",
    "    if done:\n",
    "        print(\"Episode finished!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.48453608, 13.94845361,  0.26804124,  0.17525773,  5.86597938])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0, state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import SmoothL1Loss\n",
    "# from torch.nn import _reduction as _Reduction, functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_size=64):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, action_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)  # Q-values for each action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemiGradientNSarsa:\n",
    "    def __init__(self, state_size, action_size, n_steps=5, alpha=0.01, gamma=0.99):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.n_steps = n_steps\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.q_network = QNetwork(state_size, action_size)\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=alpha)\n",
    "        self.memory = []\n",
    "        self.loss_function = SmoothL1Loss()\n",
    "\n",
    "    def select_action(self, state, epsilon):\n",
    "        if np.random.rand() < epsilon:\n",
    "            return np.random.randint(self.action_size)  # Explore\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = self.q_network(torch.FloatTensor(state))\n",
    "                return torch.argmax(q_values).item()  # Exploit\n",
    "    \n",
    "    def reset_memory(self):\n",
    "        self.memory = []\n",
    "    \n",
    "    def store_transition(self, transition):\n",
    "        self.memory.append(transition)\n",
    "        if len(self.memory) > self.n_steps:\n",
    "            self.memory.pop(0)\n",
    "\n",
    "    def update_q_values(self, done):\n",
    "        if len(self.memory) == 0:\n",
    "            return\n",
    "\n",
    "        # Calculate returns\n",
    "        states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        next_states = []\n",
    "        next_actions = []\n",
    "        for i in range(len(self.memory)):\n",
    "            state, action, reward, next_state, next_action = self.memory[i]\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            next_states.append(next_state)\n",
    "            next_actions.append(next_action)\n",
    "\n",
    "        G = 0\n",
    "        n = self.n_steps# min(len(rewards), self.n_steps)\n",
    "        for i in range(n):\n",
    "            G += (self.gamma ** i) * rewards[i]\n",
    "        if not done:\n",
    "            next_state = next_states[-1]  # Use the last state to estimate Q\n",
    "            next_action = next_actions[-1]  # Use the last state to estimate Q\n",
    "            with torch.no_grad():\n",
    "                next_q_values = self.q_network(torch.FloatTensor(next_state))\n",
    "                G += (self.gamma ** n) * next_q_values[next_action].item()\n",
    "\n",
    "        # Update the Q-values\n",
    "        state_tensor = torch.FloatTensor(states[0])\n",
    "        action_tensor = torch.LongTensor([actions[0]])\n",
    "        target = torch.FloatTensor([G])\n",
    "        predicted = self.q_network(state_tensor)[action_tensor]\n",
    "\n",
    "        # loss = F.smooth_l1_loss(predicted, predicted)#(predicted - target) ** 2\n",
    "        loss = self.loss_function(predicted, target)\n",
    "        print(loss)\n",
    "\n",
    "        # Backpropagation\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def train(self, env, num_episodes, max_iter=1000, epsilon_start=1.0, epsilon_end=0.1, epsilon_decay=0.995):\n",
    "        epsilon = epsilon_start\n",
    "        episode_returns = []\n",
    "        with tqdm(total=num_episodes, desc=\"Training Episodes\") as pbar:\n",
    "            for episode in range(num_episodes):\n",
    "                state = env.reset()\n",
    "                done = False\n",
    "                episode_return = 0\n",
    "                self.reset_memory()\n",
    "                t = 0\n",
    "                while not done and t < max_iter:\n",
    "                    action = self.select_action(state, epsilon)\n",
    "                    next_state, reward, done, _ = env.step(action)\n",
    "                    # store SARSA\n",
    "                    self.store_transition((state, action, reward, next_state, self.select_action(next_state, epsilon)))\n",
    "                    episode_return += reward\n",
    "                    \n",
    "                    if t - self.n_steps + 1 > 0:\n",
    "                        self.update_q_values(done)\n",
    "                    if done:\n",
    "                        break\n",
    "                    state = next_state\n",
    "                    t += 1\n",
    "\n",
    "                # Decay epsilon\n",
    "                epsilon = max(epsilon_end, epsilon * epsilon_decay)\n",
    "                # tqdm.write(f\"Episode {episode + 1}: Return = {episode_return}\")\n",
    "                pbar.set_postfix(Return=episode_return)\n",
    "                pbar.update(1)\n",
    "                episode_returns.append(episode_return)\n",
    "        return episode_returns\n",
    "\n",
    "\n",
    "# Example usage (assuming you have an environment):\n",
    "# state_size = 10  # For example, a binary vector of size 10\n",
    "# action_size = 5  # Number of possible actions\n",
    "# env = YourEnvironment()  # Replace with your environment\n",
    "# agent = SemiGradientNSarsa(state_size, action_size)\n",
    "# agent.train(env, num_episodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Episodes: 100%|██████████| 5000/5000 [00:14<00:00, 342.29it/s, Return=-0.898] \n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "state_size = state_space  # Length of the binary vector\n",
    "action_size = state_space  # Assuming one action for each feature\n",
    "env = SEUFSEnvironment(state_size=state_size, data=X_train)\n",
    "agent = SemiGradientNSarsa(state_size, action_size, n_steps=state_size//2)\n",
    "\n",
    "episode_returns = agent.train(env=env, num_episodes=5000, max_iter=state_space//2)\n",
    "\n",
    "# Training loop (simplified)\n",
    "# num_episodes = 1000\n",
    "# for episode in range(num_episodes):\n",
    "#     state = np.zeros(state_size, dtype=np.float32)\n",
    "#     done = False\n",
    "#     steps = 0\n",
    "#     while not done:\n",
    "#         action = agent.select_action(state)\n",
    "#         next_state = state.copy()\n",
    "#         next_state[action] = 1  # Setting the index corresponding to action to True\n",
    "#         reward = 1 if np.all(next_state) else 0  # Reward structure\n",
    "#         done = reward == 1 or steps > 100  # Episode termination\n",
    "        \n",
    "#         agent.store_transition((state, action, reward, next_state, done))\n",
    "#         agent.train_step()\n",
    "\n",
    "#         state = next_state\n",
    "#         steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13beb3790>]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGdCAYAAADaPpOnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPQklEQVR4nO3deXwURd4/8M+EkABKEpFAiAYBUVA5VJAYFl1XsoKwu+ryU3TxRlAfWS+edcEVj/WAR1FZ0PUWjwXxBFnEaLgFQgLhSjjCTWJCEiDkIuSc+v0RMmSSuaePqp7P+/WKL5zp6a6urq76dnVVt00IIUBERESkiDCzE0BERETkDwYvREREpBQGL0RERKQUBi9ERESkFAYvREREpBQGL0RERKQUBi9ERESkFAYvREREpJRwsxOgNbvdjoKCAnTs2BE2m83s5BAREZEPhBCoqKhAfHw8wsI8961YLngpKChAQkKC2ckgIiKiAOTl5eH888/3uIzlgpeOHTsCaNz5qKgok1NDREREvigvL0dCQoKjHffEcsFL062iqKgoBi9ERESK8WXIBwfsEhERkVIYvBAREZFSGLwQERGRUhi8EBERkVIYvBAREZFSGLwQERGRUhi8EBERkVIYvBAREZFSGLwQERGRUgwJXt5++2306NED7dq1Q2JiIjIyMjwu//XXX6Nv375o164d+vfvj6VLlxqRTCIiIlKA7sHLl19+iSeffBLPPfccNm/ejIEDB2LEiBEoLi52ufz69etxxx13YPz48diyZQtuvvlm3HzzzcjOztY7qURERKQAmxBC6LmBxMREXHXVVXjrrbcAAHa7HQkJCfjrX/+KKVOmtFp+7NixOHnyJJYsWeL47Oqrr8bll1+Od9991+v2ysvLER0djbKyMr7biIiISBH+tN+69rzU1tYiMzMTycnJZzYYFobk5GSkpaW5/E1aWprT8gAwYsQIt8vX1NSgvLzc6U8vq3KKsXDLr7qtn4iIiLzTNXg5duwYGhoa0LVrV6fPu3btisLCQpe/KSws9Gv56dOnIzo62vGXkJCgTeJduHfuRjzx5TYcPn5St20QERGRZ8rPNpo6dSrKysocf3l5ebpvc2eBtr07lTX1SN1ZhJr6Bk3XS0REZEW6Bi+dO3dGmzZtUFRU5PR5UVER4uLiXP4mLi7Or+UjIyMRFRXl9Ke3h+dtxoKM3KDXU99gx0drD+K611Ziwmeb8PIPuzRIHRERkbXpGrxERERg0KBBWL58ueMzu92O5cuXIykpyeVvkpKSnJYHgNTUVLfLm0WLQOPzDYfx4pKdOFZZCwD4cqP+vUZEqnhrxV7c+WE6eySJqBXdbxs9+eST+OCDD/Dpp59i165dePjhh3Hy5Encd999AIC7774bU6dOdSz/2GOPISUlBa+//jp2796N559/Hps2bcKkSZP0Tqpf7C4maVXV1iPjYAnsdt8mcGXll2mdLCLLmPnzHqzddwz/3XbE7KQQkWTC9d7A2LFjcfToUTz77LMoLCzE5ZdfjpSUFMeg3NzcXISFnYmhhg4divnz5+OZZ57B008/jYsuugiLFi1Cv3799E6qX07Wtr4aHPdhOrbklmLaHy7F+GE9TUgVkfWw54WIWtI9eAGASZMmue05WbVqVavPbr31Vtx66606p0p7W3JLAQBfbczD/b/pgczDJ3BRl46I7tDWabnaejvCw2wmpJCIiEh9hgQvoaa4oho/ZB3BpPlbEB/dDuunDnd8V13XgCEvL8N553TAJd06mphKIiIiNSk/VVoW/1q21/HvE1V1+DGr8bk0BWXVsNsFpi3Kxpcbc7GjoBzl1fXYdUS/h+mRPvJLTyF1ZxF0fig1ERF5weBFI28u2+P0/7Zmd4VW7zmKzzccxt+/zTI4VaSl38xYgQmfbcKP2a4fmEhERMZg8KKTNs3GtJSdqnP8u3lQYwPHvago/cBxs5MQUtjRRUQtMXjRSZjNdWDS/FMB1spERET+YvCiga82tX64XH7pKRNSIr+teaV46PNM5B6vMjspRESkKAYvQRj8Uir2FlXgqW+2t/ou42CJ49/Tvs92/NvmpkcmVNz89jqk7CjEg//JNDspRESkKAYvQThWWYvfv7nG63IV1fWOf4d26HJGrsJv5g71AJSIyGwMXiyipr4BY99Lwxs/55idFCKikPd52iHc/n4aKmvqvS9skuz8Mtzy73XYoOAkBAYvFrE06wjSD5Zg9op9pqYjr6QKmYdPmJoGAKisqUfm4RNun8lSVdv4va/voWpOlee8NNgFtuaVoq7B7vdvdxSU4UiZfOO2hBD4z4bDTrdlA9VgF9h4qASnXLzqQwb7iitQ0GLsXHF5NQ4d07fXUgiBzbkn3Da6Qghk55eZ2ijvLCjHB2sOtCrb9Q12rNt3DCebpW3Kt9vx5FdbA9pOTmEFyqrqvC/owrTvd2DDgRJ8+MuBgH4fqANHK1Fe7Vua7/44A1tyS3H7+xscn9XUN2BbXmlAdaORGLwYTK+p0rX1/jdQerjm1ZUY88567Cuu9Licq3dDaemWt9dhzDvr8d3mfJff3/7+Box5Zz2+2JirazrM9GrKbtz89jpM8fP5QoePn8To2WuRNH2FTinzruRkrePfzcv2+v3H8cyibNz2XlrQ23hvzX7c+m4axn+6Meh1ae14ZQ2S31iDoTOcj8GQV5bjupmrnPJHa4u3FeDP/16Pm95a6/L7ZbuK8Yc5a/GH2b/olgZvRs3+BS8v3YVP1x9y+nz2in0Y92E67v+k8ZhW1tRjwcY8fLc5H8Xl1X5tIzu/DCNmrcFVrywLKq1VBgbHuwvLcf3rq5H48nKflndVjh6Ztxk3vb0O767Zr3XyNMXgxWDNAxYrT5XeUWDuG7P3ng6eFm11Hbxs/7Uxfd9k/mpYmoz23prGK75vN/u3j9n55j/9ufmVc0OzK8BDGo6VmrehMXBdv1++LvNDXmbjHdSx92XRlsZzZv9R19tYvK0AgPc0GmFHgXNZ/SKj8Zimn+6ZszfrJfW3I2H1nqMA5Lkw9MXqnMY0n6oLPGBatqsYADB33SEtkqQbBi9manEycRyoGrwN2D1WWWNQSoioOb2q0OM8p6XD4MVgzdu9lhcCigylIA8+TzuEwS8tw5upe7wvTESa0usCcPynm/RZMQWMwYvBmneBqzLwk3w37fsdAIB/Ld/rZUkKVoNd4LvNv+KwwtPuSVt6vXJla16pLuulwDF4Mdg/l+x0+11NvR09pvzg1EX54OebcNdH6U6BTtOMi+2/luqZVK/eXrkP37sZU0LGm7VsD6b/uEvTdX6b+avPMxf04m5s2Neb8vDkV9vw29dW4fMNh1GhcTpP1TZgzDvr8dYKGQNR9S583kzdg0fmbcbCLa3LlBACs5fvxaqc4qC24UvPy4Gjlfhu86/Sz6bxZF9xJRZtyW91Abxm71GTUmS8cLMTEGqaTyN2d+oMemkZDs0Yjeq6Bvy0owgAkFtShQvOPQsA8NOOIjyzqPGpvYdmjNY1ve5k/VqG135qfKbMTZefZ0oa6Iya+gbMWtbYyN43tCfiottpst7JX2/D77bHYu59QzRZn5YyDjV7ivWibGQcLMGcO67QbP1fZOQi8/AJZB4+gUnXX6TZelV38JjnmYTuNPVG/pB1BNf1icUnzcrUTzsK8cbpW63B1Gm+9Ltc//pqx7//fOX5AW/LTMlvNO5D2zZhGD2gm+PzdfvkG3yuF/a8KGhPUYXZSUBJlX5TNcl/zS/AAnmuiycrc9S4mvt5R6Gm66sxdZaJvL0Ch44FP8toVYsy9euJwJ4p1LLnwZ+nX8vwPKpgbdOx9132UQ0MXkwke+EgIllxaqIvgqljOftTbgxeTMTYhYgCw9rDXwxGrIXBi4k428h8PARE1sEAJXQweLEIvaYIkhqsHIRZed9IW56CF5Yja2HwYiItzyUrv2pAT7xSa41liVTV8iLO6ue3xXfPIwYvZlK4jfB20vAqh7Ti9FRqD+XKSkWO549vWmaTlsGKCsdA3yTKnQEMXkwU6BVuKEfbpD/egiQi2TF4IV1YvbuWzBEq5SpU9jNYLbNJy2zjMZA7Axi8mMhbt6QK3ZZERLJo+ZA61qHWxeDFRD9m+/5EUHblkydWHmTrrgHiOUEteSoRwfakTP9xFypr6oNbicZC+Qxg8KIIKzdORE3eSN2DSfM3w+7DJXMonxPsUXBDx9b8vdUHMPP0+9z8wed56YMvZpQY77nqL5B6RcbjYpVeiNmnX953XZ8uJqeEVKT3WbC7sFznLfiHs42INCbLxYYe6ZBl36ysVoOXIgohkJ1fhlO1DRqkyFgsY75pPVVaviBeyzQ12AV7ck5j8CIxc99q61mD/cwJJIR5J5QQAna7midzdV2DUz6qprquAW+k7sH2AN9sW9dgR3WdfoHFd5vz8Yc5a3H7+2m6baOuwW5K+ZOwjdbNiZOBvcG+qLwa/161T+PUmOdUbQOGzliOCZ9tMnzbtfV2VFTXGb5dTxi8SKq6rgFX/PPnVp+n7T+O11P3BLXuVTnFSHxlGX7Ze9T7wm7Sdt8nGx3////eTcPdH2eYEsBM/DwT17++CjX1gTWCZjUCJ2vq0f/5n3Djv9aYkwANvLf6AGYv34s/vbXO798KIfCbGSsw8IWfAz523ny5KQ8AsO3XMhSWVeM3M1bg7ZXaNWY19Q1IfGU5bnrb//3XQsnJWvxu5irMWhZcfdDSun3HNV1fMD5eexBXvJiKD3854NPyzU/nez7OwHurffud63XpVznUNdjxp7fW4qlvtvn8m9V7jqKovAbLdhU7PjOq+vrtayvR//mfUXZKngCGwYuk9hZVwtUF3bgPN7hc3p8T7d65G1FUXoO7PsoIKG2Zh0+0+v9f9h5DdZ3xPUWpO4tw6HgVnvt+h2HbDDbgOVlTjynfZaGuQWBPUaXj82B6IZoPXt1dWBFUQODrQNg3g2w0iytqUFNvx+HjVV7S45vaejtGz/4Fu46Uo77BuSzOWrYH+aWn8FoAAy5bmrvuIIZOX46lWUdQcrIWWfllfq/j8PGTOHz8pMvvqusavO6zEMAHvxzAwWMnMWvZXr+370ltgzw9vv9cshMA8NIPu3xavvm5ubuwwuk7me62rN13DNt/LcNXm341Oyk+OVJWDQDYnHvCy5LG4YBdxbjroZZh5oWZXdkLNubhTwPjMbR3Z/MS4aNnFmXjv9sKnD5buOVXPPHlNkz/c3/cMaR7UOuf8NkmDOnZKah1qGpHQTlu/NcviAwPQ5eoSMfn9Rre2nnhv40N6otLfGtQW6qpb8BvX1sFAMh5aSQiw9s4vss9XoVrX1uJ+Oh2Xtej0i3HV1N2G7Id2Qeun6ptwO0fbHB5q3FrXile+WEX/jH6EgxMiPF73SnZRzRIoTrY80KWsfOIXDMB3Plhe+tK5okvG7uPp36Xpck2Mg6WaLIeVdXU25FXckrXbQQaPFRW17v8NwB8lnYIAFBw+krXKv69ar8h2/F0AWXWxVXz2+lfZ+ZhW16py966Me+sR8ahEtz6bmBjtN7S8JaoChi8SGrTYbUbHxl6gsjZfzYc1nTMR0sZB0vwj4VZKNd4YJ/c19JEvvM0i64pGPb3tl12fhke+HSj0y1oLch0m80VBi+SauqabuKuO1TP2Rr+CmZKamVNPVKyj6DsVB0e+HQT5q47qEmaqusasCqn2JFPQgi36aysqcdjC7bgqpeXIa/E8zgMPfWY8gOun7kKpVXuZ1mcrKlvNa7Dm2cWZeO1n3Jw+PhJlwFGfYMdOwsC77267b00zEvPxeunx5XsP1qJ+z/ZKNV9cqAx7xZtyUd5s8GH1XUN+HpTHvJLte+tEUKgoroOZafqNFu/u16Eypp6n3uEms6J4opqPL5gCzYeMv6C6cDRSsxatgcV1do8udb7K1eCa5EDuS0VyFRpf9J5y7/XYdmu4laBkUxtgx445kVxfael4C+J3THw/GiPywkhfDqJ/rutAJtzT2Da6EsRFua8fNmpOny1MQ+dzopw+dsrXkx1/NvXk7xxmjXw6BdbsGL3mVH0y3YV4d6hPZCdX46ETu3Rrm0btGvbxum3LQOMLXmlqK23IyL8TEy+6fAJ3Dt3I24ddD5eu3Ug7vwo3Wk2RfM6ot9zPzn+/cSXW/HNw0Od0unLvnhTWlXr05XVgWMn8eEvB/G/I/o4fV5d14CaOjsG/vNn9Op8Flb873Wnt+11lQ7Tvt+BNXuO4t07B2FkvzgAjYHLU99ux3eb89E3rqPH37sqS80rzkOnB+A+Mm8zdhdWYMXuYhyaMdqR/shw52smo6/w/v7tdixpceuu77QUx7+fHtUXE6+9UJNt1dbbMfW7LHy7+czAzHkPJDr+LQAUllUjzocxLs3d+m5aq2NQWFaNq6cvx4Dzo7F40jCXv1u//xi+yMjDryeqsCW3FG+OHYilWYVI3VmERVsLsOufI/1KR3NHyk5h5k97cN9veuDC2LMRGR7Wqg5pzm4XuOHNNS7HI1XXNbQ63z15a8Vep7FD7jR/JYurYtdgF8gtqULPzmd5XM/OgnL879fb8LeRfTDognPQoW0bhLdx3RfgrV54f81+bDzkHOBP/S4LM8YM8Pi7JnUNrtffd1oKXry5H+66+gKf1tOSq+ZiybYj+J0kD5Bk8KIQd12O89NzcVl8P6fPMg6W4NWU3fjnTf2w8VAJ5qzYi/kTrsbFXV03TCdO1joFH4Mv6ITRA7o5/n/1nqO452P/ZieVVtXigU834ZYrz8O4xNYnkBACd36UjhMn61yOV/ks7TCeW9w4iyiiTRhyXhrpVGGn7ixyWv6H7Ufww/YjuPPq1gNev878Fa/dOtDnaaDFFTUAGq9k//zvdU5dsgWlpzBy1hrcP6wnbhucAKCx8vxk/WGndYx5Zz3mPZDoqITtdoHL/5kKX9XbBf76xRb8d1sB7hiSgHuG9sDIWb/gnA5tATQGOL7qMeUHx7/X7GmcIv/QfzLxf2P6wwYbnvp2u+P7lrM0AOA3M1Yg6cJz8U1mYyO89u+/c/p+wAtnAr/Ve446ba/JL3uPOma43XLFeY7P7/ooHe/dNQivLHU9ANZd1e/PVXBTugG0ClxaemXp7lbBi90uPDbEOwvK8dzibPzvDX2Q2OtcAMD3W/Px2IKtrZYd92G649+DX1rm+PeQHp3QK9Z9o5nSrOG1C7SK+poGbG7/9cx4ivX7juHNZXvw8i39cXHXjvjLB+lOv3niy23o06xO6P/8T07f55VU4fEvtyIrvwy19XY8nnyR0/f9nvsJn48fgiu6n4Ok6SsAwBGoDenRCV89lITjlTUu96fX00tdfj72vTSkHyzBVw8mOX1eU9+A297bgG15pY7Pvt9agHuH9sDMnxtnvnkKOp79Phs/7ThTZ8xPz8UtV5yHq3qcGdw+af5m/JhdiFf/n+fAYcJnm5Bfegr3zT3zyIgDr4xyWUY++OUgTtY24JVb+rtc1ytLWw9mXrAxr1XwEsiYnWmLsl0GL7sLyzFy1i9On932XhoSvQz0/3bzr3j9toH+J0QHvG2kCAGBDQfcN7wtK/Lb3kvDpsMncPfHGXhu8Q4cq6zF0x4GgzYFCU2On3SucPwNXADg7ZX7sOnwCfxjYbbbZdbtO+52oO2n6w85/l3bYPd5xsh/NuT6lU5PvkjPbXUv+acdRdhdWIGnvjnT4M/8eQ+OtaikMw+fwOKtZ2YV+Xsve0dBmWNW0hcZeXj+9DE6UaXdmJK/f5vlFLi4k196yikAaPmOF1+myU9bdKYcLNyS7/h3cUUNbvn3+lZXnzLZktc6bc0bk3vmZmDjoRMY+/6ZRxm4Clw8yThUggUb89x+/9B/Mv1aHwD85cN0bDx0AhN9fLBZy3PsmldXIvPwCceFU8tp2ZU19Rj/6SaXvQsZp29DNQUWvko/Pdh8+o/OweySbUecApcmT3y51fFvT+/Eah64NBnf7HlVwJmemfdWex5gXO7ieSfpHgbJz0/Xrk7Swv1zN7b6LONgCeasUGfQL4MXhQTSu968QfX0+xMexlcEqrJG/XuuwU6xrbMH/syMlj1tQaxKc5KP5dOcu675JkcrXPcuyOJ4pXbnd8sOgDovTwLXagC3u+Bfy2DeG08TEWR6Po43xzQsD2Zh8EJkAaH0uPgmnNFGIU/H856zjSgkqdKwhGKjTxQMmc9s2RvcYLjcNwvvrzcMXiyCjbC2VAm+mli50iYiaonBC7kkY2MoY5q8kf1x5SpQ8biT2gRcXxA6zmcTTmteoDpj8KIQll1nPJnNE0hA4c/DumTr+VI9gNIz+UZljbvSY8bb7Ml8DF4U4e0KnucvEVkJ6zQfhPAFHIMXCmkyV5Ch3LPE221qkeU8CuVzJtQweFGIJPWDT/SozFSsmJqnWc8KXqWy4S8VjzupTZkiF8J1CoMXi7NyxS/L1R4Zp/kxZ++Ms0BeABgI2caY6JUayXaTWmDwEkKMr3SC254MdYeZA0dlrjwDaScDLX8y54NMzAoq9AqZfC1jzRezcllhqO6MwYtCAim8Zp3MvlQ8/qat5fKq9Sqpll5PZC5XRpEoKYZq2cNjdrygR4+T26nSsh10HdMj2662xOBFEVr0ABjVrdxsiyb+2sdteNkIb01ox/jyR3qQ7Sga2eNk5Z4d1TB4ISIi6TBQIE8YvJAuWPEEjx0Vnsn2IDsiK5H97NI1eCkpKcG4ceMQFRWFmJgYjB8/HpWVlR6X/+tf/4o+ffqgffv26N69Ox599FGUlZXpmUxLYEOnLQZfpBrDZhsZshVqyWW+h/DB0DV4GTduHHbs2IHU1FQsWbIEa9aswcSJE90uX1BQgIKCAsycORPZ2dn45JNPkJKSgvHjx+uZTCUYPfZChumQRqRA791kTBm85j0sEhRLB4mSAsDcc1aWvDCqN47ntfnC9Vrxrl27kJKSgo0bN2Lw4MEAgDlz5mDUqFGYOXMm4uPjW/2mX79++Pbbbx3/f+GFF+Lll1/GnXfeifr6eoSH65Zcr2RozNm74ozZYR7zzwZjuWoUVSp/etZfRtWNoV7/udz9EM4T3Xpe0tLSEBMT4whcACA5ORlhYWFIT0/3eT1lZWWIiopyG7jU1NSgvLzc6c+qAnsZnq/LyXcWyJei4EgQ/5pKi+MpYTEli2JRk5tuwUthYSG6dOni9Fl4eDg6deqEwsJCn9Zx7NgxvPjiix5vNU2fPh3R0dGOv4SEhKDSrapQbxiJKDQ1r/r0vr3O4FkefgcvU6ZMgc1m8/i3e/fuoBNWXl6O0aNH49JLL8Xzzz/vdrmpU6eirKzM8ZeXlxf0tknOnhgVBZON/lTERt/W1Lt0+JJvfAaPs5A9Z3nhpgsZhkp44vcgksmTJ+Pee+/1uEyvXr0QFxeH4uJip8/r6+tRUlKCuLg4j7+vqKjAyJEj0bFjRyxcuBBt27Z1u2xkZCQiIyN9Tj+5pnVBlbzck0IYpMjNuHcqeV8mVOO3UOR38BIbG4vY2FivyyUlJaG0tBSZmZkYNGgQAGDFihWw2+1ITEx0+7vy8nKMGDECkZGRWLx4Mdq1a+dvEkOSL6Ps/QlQtAlm+G4jVbetB3/2pnnxs1o+6EX2K2XdBPHmdk+BV4jmpjJ0G/NyySWXYOTIkZgwYQIyMjKwbt06TJo0CbfffrtjplF+fj769u2LjIwMAI2Byw033ICTJ0/io48+Qnl5OQoLC1FYWIiGhga9kqqMwF6Gp306tOJv0vRoxHilFhiJixUZzOzZRk4vZvSzZLpNu4QFPGRvC7qh69zjefPmYdKkSRg+fDjCwsIwZswYzJ492/F9XV0dcnJyUFVVBQDYvHmzYyZS7969ndZ18OBB9OjRQ8/kSk3vdxtpfWI0rk7+dxt5o+Uti1Cve6y2+2xMrI1HV266Bi+dOnXC/Pnz3X7fo0cPp8j3uuuuk7brU9JkUZB4XMkd3q5yzVWjLmu9rbUQ2U0A8gfnfLeRIrz1AHBQI1Fok72x0Ysu8URoZqVSGLxYnFn1mepXKHqkX/U8kY3ePSO8IDCXjKeLmfGhq94tPcuo7L1pDF5IWnKfOr4JpnJh49lI1jpUtsrdqPSYtdcynQ+y9HKF8q1NBi/kkoynRMu6WZYKhEKAixNCpfKn5/ksU12hWfwm006dplJ5MwKDFwIg5y1eGdNEQeABJT+wuJAnDF7IJVYcapHwQjEofD2A/3hlri1mp9wYvFhEsPc+rdb4SYMVIFmcUUXcbR3X7ONQCzhCOYBn8OIjKzTusg0w9MaI1Lqr7FTLKyX4kaXMfuOo3uAb+VbpUCL7KcjgxSKCrew1fzFjs/+qLJRH85NaAj2HtTj19ThLWq7TXWASzOsBAr3VpnrAZwUMXhRi5FWFEU22DL0bEiRBSTIcO0OxsXJomRWml4Qgjo2ncuzqq6agxYzi7/LJxgHmvhUuyhi8hBAj322kBRlSxHcbaUiD/TctZlK/rteMzFkRajF1KGPwohA9o2V92tVQb62d6VmxstI2nmylW8YLENJXoBdXVhgbxODFImSrtyRLDlmEkeXcCl3regiVc9tVWQuliwTZjzODF5KWmfVECNVRRGozY/yJCS076yRnDF4UolJXn+onWihdYQVChlsUZr+YkUVEX61y3/wiF1JkL98MXnwUcrMrJKTiIbBqfav3+SBBbEQmY8+rfqxwS5TBC0nLW/tl9QbOr/1ToC4K9HDJcOHgKgUqFT8ts9D8o+GeBEVFNyqVNyMweCEA1g8EyBqaN04q3Ua1OkOCBu9vB9C9HrNKPWmFc4fBCwGw9hWLqqxSUQaC5dE4VipnWu2LhbLEshi8WIS7yt7p0dmeniapbXI0Ye49b222HszAVqs14FrsjpUaWjKfxwd3eghhWAzNx+BFETab54pbznZO31QZ0bibObDNasELyUmZcsaIwVCylwsGLwoxsjDJ9qJHQM0R8jIMNtWDNffKPbabZ8icF/6ebgG/zDKgX2kv0J5IFevSlhi8WJyvRdSMCslb2kJ9tpE/VKiMVD5c8ueueXSLz31csR7lSkC+cyrUn/jbEoMXH5ldRrwVUl9OYM8vZvQvPb5RublqFOyo/GDGvDA4k1uoHh+z60JPQrkx9wdnGxFRSFK/6iPphWp0SD5h8EK60OLx8abONuIVHJHPZLvFojdTbrOHVhZ7xeBFIbwQoVDRvKzLWmnLmi69mVUNGb1dFW6t6NkmyN7eMHghXegy28jI2VYarceo89/ohjRE222SkB5lUfJ2O2i+9JTJHpwzeLE4K5+EVt43K/LnVqJsFaer9Mh+ZdqclW/r6PNYBvmoVN6MwOCFpBXq5yorq0YyNiShzLDj0SIoYTloLdC4TYVbYt4weFGEFg2ZVR+YZlVWqGCaY/mTUygHyVpMLCBzMHjxkdXrXX32L7iVWmG2kdPAUz/3yMpd/UT+kinMkCXokSQZpmDwYhGh2MwZsc98txGpIuBHxStezvQKJEI5MFABgxer0LgGkrE+kzFN3hjVMKiYNypRoSEzqqwpkBU+8/dWZtOtXNVvgfo220jufWTwYhVualef322kcY3ky3aDPTesVImGAlm62gMheT1uKgGhT/6YWF5kbLgVPn10weBFEVqcSx7fbRT86jVfqwznavDvNtIoIUREGrHCZAAGL0QkHTWCPiUSqa4Arti06jGx2WzsbZMcgxeLU7l6NWZArplb90yNBtxYbFDMZ9YhkOG2Y9NYETPSwrLvjMGLQow8XcyvJogayVtpy5UwCdp2IsMwePERn7nhHz3qUT0G0blLpx7PedGTjAMM9dA8P9lYOzNrtpEVxk+4YuXyZYX2jMGLIow+kYIt2oacGorVLpaKLwLYF3+Olmx5pXplr2d+GpU37gJ0fV4Cq/bxDgUMXhQSaqeTWqEJ6cVd42h++8ISKgMji4GZvUyurtUCTY0VessYvIQQ1a4m1Eqt9qxQwTQX6sdTVv52YFrpOMowCDgYVjoW/mLwQgD0OgnUP7WC7RIPJgBR/VYFGUvxdtgrmQINeVISuhi8KMTjCaNYr4omdNxn1XLT8PQaWHs3P8yhWMz1pnqeyhJIyJKOUMHghZShYh3L3hNrUOEWHt9tpF0dIVMvjx6sUC8xeCGXjBgfE/QJpEEFo/4pbBKdZxs5/U6C6dFWqOz1YnbPTTCBRqAzmFx9a0Y26Hk6yF7iGbz4yOwTVAuGvttItF6r/29wNV/Q7zaSYi/UY/ELX9KQahMRAqVlXWKFeonBiyJC5Px0EoK7TAphgBV6mo45D735GLyoxMAzxur3fJuExl5SKLD6KWvx3fPK1a3LUL7AY/CiCJsNoV1SDabLUzs1X2OzdVu4bLjbN70ba2/jXIzKc9lui7RMjV7HIZC91jurJDsUIY3BCwFQIy4ysuLQbtZCEL8N+WvN1th4hC53hz6Ui0SgNYQVBqAzeCGXgr7aY7traYFUfv4EcjIEKaoFj2bmmQzHi0ILgxfShwaVmbemQ62mxX9WG8PgTwPXPDhq/jPTpkor3jh7Sr6/edpycZXzRqWxfZxt5IzBSwjx1JsiYwUkYZLoNL0rP1/Wb3aZla3dky09wWq5OzLtntXyWkUMXlQSwAlj7pWF/OGHtxSaeW840J4KIiKrY/BCyrL67B0GJKfJcDCI4LnHhZ0xxtI1eCkpKcG4ceMQFRWFmJgYjB8/HpWVlT79VgiBG2+8ETabDYsWLdIzmUQkGXeNhFlxjJVvE1gpNmTA7xsr5JOuwcu4ceOwY8cOpKamYsmSJVizZg0mTpzo029nzZql1GAqs6lfFH0QEjt5RqtxHxKdDnrPNiL/WSkIAXw/3YMpVm7fbeT1d/7/hrQVrteKd+3ahZSUFGzcuBGDBw8GAMyZMwejRo3CzJkzER8f7/a3W7duxeuvv45NmzahW7dueiUxJMj2gKvmvCVNhtlGUo3Kl/dQ6qtZ1MPZRmSUkL94lrzM69bzkpaWhpiYGEfgAgDJyckICwtDenq6299VVVXhL3/5C95++23ExcV53U5NTQ3Ky8ud/sg1jy9m1Pg8bbwyb/liRn/XoT8jqyeZA0lSn9XbWpn2z5S0aLhNqS7KAqRb8FJYWIguXbo4fRYeHo5OnTqhsLDQ7e+eeOIJDB06FDfddJNP25k+fTqio6MdfwkJCUGlm0hJjIsMp371rx1TZ+WZtmWDudhRmQI6o/kdvEyZMgU2m83j3+7duwNKzOLFi7FixQrMmjXL599MnToVZWVljr+8vLyAth3q2CngjL0kEnFzLMyuuFlCjOXulNTjVLXBdR0gW7UgW3qM5PeYl8mTJ+Pee+/1uEyvXr0QFxeH4uJip8/r6+tRUlLi9nbQihUrsH//fsTExDh9PmbMGFxzzTVYtWpVq99ERkYiMjLSn10gIvJKlhkZQpgfqDUnR664FsqNuT9kKdvB8Dt4iY2NRWxsrNflkpKSUFpaiszMTAwaNAhAY3Bit9uRmJjo8jdTpkzBAw884PRZ//798eabb+KPf/yjv0nVlKonhc1mUzfxLehxwun9srdgBv3J1GBpwZ/77EZeZZOcDBmQ7+dJZrVzUmW6zTa65JJLMHLkSEyYMAHvvvsu6urqMGnSJNx+++2OmUb5+fkYPnw4PvvsMwwZMgRxcXEue2W6d++Onj176pXUkGG1WyGsSNTiT/Dp7t1GRmoebCl/5njYgWDPI73yxsw8V/54hwBdn/Myb9489O3bF8OHD8eoUaMwbNgwvP/++47v6+rqkJOTg6qqKj2TQT7gyUoycddLI1PAKlFSDGXWfht97D33ypiQCy42GWieWGG2kW49LwDQqVMnzJ8/3+33PXr08NobYLXegmCoV+DUP3aq3BtWI5XaYtVAgFwBLRmH7zYickWjhjG4p39qkwYVNW+QZMgHto/ykqF8ACwjRmPwQsqSpdIiUhnPI3UFeuxU6VH2hMGLQqxQ4IKh1/Mc9CTc/Ft1gRwL9W57kq/MDICceun8/G3gwxJcPAMmwDVRYBi8WIT7qaXWPaV4rzv0mFWcrXsWkcr0rANlL/MMXnxkhV4Pj+820meLuqzVSMH2FhiVAxaOURmkhqiWZVqucmB8YrTcohV6QRm8KCSQAmfWm1H5yvjgyVVZy6F5njB/QovRAboexSuYfWD96YzBCwEI3RND7yfsWpWRgYOsvUoMnuQga/kgfTF4IVKEFW5d+kqFBkmFNKrM1+BQr/NCj7XKEvBaoS5h8ELKMPJ002qgsyyVldbYcFuHlcqov+XSrNvqFDwGLyHEU4Pc8jsVGicrDDrzR6jtr0zMnLWnxZa1vNJutSYF6gp/qVD/hToGL0QWYIVuYHecXtIo0W7yov0MIw6LTPltRlqMnm0k+2M2dH23EWlLppPXN3IXfl9oesWqfnYYRr2yfoYQAkXlNWYnQ3m+ni8q9UiyDtAOgxcfyVDoZEhDqNAqq1WqWGXVvNybFdT4Mzbin0t2Yu66Q/olxmR+HwIF6y2bzf/9tNqZLvt4IN42IpckL7cAtOkVUWA3yQ1Zg3mzApdAy7Lf+SjZSdO8HpC93pIlfVa4zczgxeIkOVc0Ifs9WFesUEm4EtC7jaxUGENZy2Mv0XH1t1xqWadY80yXF4MXiwv4tWMGnIkyxCISJIEUoELgbFoKDdqwu1uwzp9rkxgFDnfIY/BiEb5Urh7fbaTLZbG+l2RGjCcJ/t1GxlyWGv7odJOutmUY/0LmsGovphmsMNuIwYtCdH2DqOQFlUIXg5TQZPYTdvXAalY7DF5IF67OUZUCJIWSaknN81/WY8GZZPqS9biTHBi8ECnC1RVmfYNdqaAwWDL1wsh2xW9m1qhaBj3fStdjexqvL8CjLlvZDQSDFx+pf6jVrWCaGPpuI422pndjO/jlZXjg0036bsQFxYuST6xQwftCpoAwEHqVxVAo4ypj8EIuhUrFbaggXxrn6iqrtKoOy3cX82jpTIX89ZRGPRtio+oKmW7TyZKSUK6nGbyQjvQ9sVS/YvRG9Z4yrZiVC7I0lrKVA7lS41wPSJZV0pKlbAeDwYvFqV9EzRXKVzZmcheYytQ4WaEBIO34UhqCKb9GP65folPNJb7byCJ8Kdibc0sxd91B39YX4hWzVo1kaOeiNoQAjlbU4JvMX1FbbzclDSocRxXSSNoK5XqawYtF+Nq1/MJ/d+qcEuPIdBVO+nrgs03YlldqdjIsyd/zqGVz6a0BDbT30uxez2A6OvYVV2iXEB2Ynbda4G0jUoaKwYqCSZYSAxeJWOhiX693G+0oKHe5jErj9GRPKoMXcsmIyNwK0b+hPNQmsg3qJONZrQS07NExsuFn3SQ/Bi8+kqFxCOTcNT/V+tGyMttXXOl6G0G/20hDVj6YklMt6z9e69vYtoCIlv9rTFPvrgp2ehqzzmkwetCsXqwwVobBi0JqPAxWlLNyVeMEKTtVh+Q3VpudDHLDIu2Fof65xDpj26xEgmtgn8meVAYvijh+shZ3f5xhdjICtmhLvtlJcOtI2alWn8l44mYcKjE7CYapbzgTqMtQ4Tc0CNz1UTr+L2W32Ulxy1OMJwBU1dYblRRDebqo88ZdT0rQPa4SRdxr9x5DZY31jj2DF0XMWrbH7CT4pWWD8/iXW6UMCIzE++i+e/GHXWYnwcnqPUfxy95jeGfVfrOTEpAGu8Clz/5kdjLIBHd+lI57W1z4WqEuYvCiiFO1DQH9Tp74P3gqnnDBXID5c/UmQ++Elsx6nos7sqVHSxJ1Ejgx+3x3lS3Bjn00K683HT5hzoZ1xOCFALRu/GRoDI0YJL0trxT3zd3oYuPab+u/2wr8Wl7SNgWA+Q2LEVTbR7VS6z+ZgixZ0rJsV5Fu664K8ILZKAxeSEc6v9tIo/UcKavWaE3u1dbbMe37HX79xuqNka9kCCLMTMPhkirTtu0LGS50tGbUDKpg7S6U+2F4emLwYhFaXwjIcGUhw6A3raqwLzflabIeMoerBtqo4rm3yLcGyqizReZGXe/eWk91kt7vNtISp0qHELPLnNnbDzVaX3flFLp+4qbHNMhS07lgaOUnQTZIEEdLi3ljDGazMwYvFiFB/W44NfaZVQ5Zi+uBrO6XDzQGV7l3QPaUq3FTzDMGL6QOJc83JROtCxluA1JrsnbwZeWX6b4Nvd5t5G6tPAW0w+DFIuoagpvK2TISl6FCk/m2ib9Uvop0xQpXblZj2BGxVlF2yWa5M9Z6GLxYxPtrdHyXiU6CjU2MqFyCrcI+SzsMIQKbu8CeCnmYGUfLHsPLnr5ABHK+ZueXYeGWXwGERHxnunCzE0DaOFZZ4/i3P0/jrWuw40RVrR5JQrCnsBUa7/X7jyNt/3Gzk0FBUqF9NuxsMSkzCg14pEEwXvspBwDQpWM7l98LIaQJ9BovyiRJTIAYvKjCj3I2a9len5f9vx9340M930CrKC0rmbwTcj+ng+RmgRheE9N/9P5eKX9PWz0ukPYWVeDcsyNbfb40q1DzbYUy3jYKcXoFLq66XWW56jCaENYb80LWYaXgqLpO36fCBpNVuwN4XIJerDBmjT0vPjK74T3a7LZQqDLyENTbBZLfWI1hvTt7XO6LjFys2F2sSxr8qSjNLp+hyIgnM5N/quvkeAeVlQJCWTF4UcTBYycN3Z4MJ5/Zs432FVdiX3Glx2WmfpfldT2MK4isoelc9taT6qrqEkKOetUqeNuIXNImbtD7Ud26rl5TKqVVNmYFf83PAfZseWGx/GkMNAI7aS2WFTh83NgLZ18xePGV1UqkAqww26hJII3f6j1HtU8IEfkkmJ5fd1WXLEGwP2PwfOldNgODFyKSmtm3Dyn0BHPdpNcll1nXcidr9R0EHSgGLz5SdXS2hTovWlGlTTPiXreq5ZO8U6Wckzr8qi8kLYAMXkgXepT3YNeZcbBEm4RQQLSO34yMy60cHOrdNkna9gUlkIuROrscM6GsgrONyDCbc0/4tbzWtwvu/jhd0/WFMis2SBR63NUxeSWncKyy9ZPHfY1ZXI0peW/1AVzZPcaP1JEn7HnxkaqVdaDpDnZ3XV2Z3P7+Bk234a/6BnMO4gv/3cFH1OlA0VNSF6ty9HnWkC+sehzeWrnP7Xee6lUB9z11m3NLg0uUCWQ9vgxeSEf6vttIlfE8NfV23SuABRvzdN5CiJO1Bj/t3rkbjduYIuedL6w0o9EfVnjiN4MXH0led0mnoroeX2Tkmp0MJ2YeQ7177t5ZtV/fDYSY45U12FNUYXYyDFFU4eeTgl09gI01pBMZg4O3PfQkuSPrM14ABi+kkxk+vESNSFaDXlqG77cWmJ0MAEDpqTrY7foFB6VVdbqtOxTJF7Y0anrrNeB7sFlTL+8gY92Cl5KSEowbNw5RUVGIiYnB+PHjUVnp+VHrAJCWlobrr78eZ511FqKionDttdfi1KlTeiWT3Gg6AYUQqDWpALccTKfy1Z3VeqdzS0LrTdllp8xr4Kd+l4X7PzXwthC5VVVbD0D981nVMZzN6TbbaNy4cThy5AhSU1NRV1eH++67DxMnTsT8+fPd/iYtLQ0jR47E1KlTMWfOHISHh2Pbtm0ICzO/gyhUH5R150fp2HTIv1lCessrqcL0H3chun2EX79TvL6Ryu7C0Lil0mS5Ti/f9NWqHB+etqx6i6qAjT7UhVZrKWRt+nQJXnbt2oWUlBRs3LgRgwcPBgDMmTMHo0aNwsyZMxEfH+/yd0888QQeffRRTJkyxfFZnz599EhiyAi0Pmsqr+v2HdcsLVr5n3mbkZVf5vfvJD0HibQhaytjMZmH5bqYC1W6dGmkpaUhJibGEbgAQHJyMsLCwpCe7vpZG8XFxUhPT0eXLl0wdOhQdO3aFb/97W+xdu1aj9uqqalBeXm5058eQq1aqG/Q/1aRt22cqnP9WOpDBr9hWws7CvQpl6GAbTLJ5MHPM81OQtCs0EmnS/BSWFiILl26OH0WHh6OTp06obCw0OVvDhw4AAB4/vnnMWHCBKSkpODKK6/E8OHDsXfvXrfbmj59OqKjox1/CQkJ2u1ICJv58x7dt5H8xmqP3xeV1+ieBqOE+tWaWeOmSAcWaPiCcayyBkfK/JyhJRkrXBD4FbxMmTIFNpvN49/u3YHNMrGffnTygw8+iPvuuw9XXHEF3nzzTfTp0wcff/yx299NnToVZWVljr+8PD7vQhWunmDpCwucd05CYTxVMANe3eVOiLehJCkb9OnZ0HL6tRVqHL/GvEyePBn33nuvx2V69eqFuLg4FBc7D3Crr69HSUkJ4uLiXP6uW7duAIBLL73U6fNLLrkEubnunxcSGRmJyMhIH1IfnBBoX1rRc3omhR6tK/SFW/K1XSH5xs9qQeVZgiTv8fMreImNjUVsbKzX5ZKSklBaWorMzEwMGjQIALBixQrY7XYkJia6/E2PHj0QHx+PnJwcp8/37NmDG2+80Z9kkkYGvvCz2UlwEooBJLlXz+DamYkDGVQ+N+12gb98uAFdo9ppsj6Fs8Kl7Hw5x+vpMublkksuwciRIzFhwgRkZGRg3bp1mDRpEm6//XbHTKP8/Hz07dsXGRkZABof0/y3v/0Ns2fPxjfffIN9+/Zh2rRp2L17N8aPH69HMv0ia/Spp4qaerOT4FJlgOlqYGNnmr3FgU+t/jztsIYpsbAWEcTs5e7HCmq7WXXPK7sQ2HmkHBsOlEjzUMImtfV2vJG6x9Txckcr5B13qNtzXubNm4dJkyZh+PDhCAsLw5gxYzB79mzH93V1dcjJyUFV1ZmHXT3++OOorq7GE088gZKSEgwcOBCpqam48MIL9Uqm5Slcr5CF/OWDdFwWHxXQb2sNmPlmRW+k6j/oHgA8XROs3XsMp+rkPX71DULaOvKT9Qcxe/lezF6+F4dmjDblAjpP4odR6ha8dOrUyeMD6Xr06OEyYp8yZYrTc14oOFbqWr9u5iq8edvlZidDc3klofEEaU4XtwgXd6ca3EQAd37k+tEY5N2+Yu9PpDfDnqIKXNy1o9nJ0C94sRzrxADKqq2345H5m81OhuaufW2l2Ukg8llFdevbtoNfWmZCSuSkx8ijpVlH8D/zgq/7bnprLe4f1jOoW303vLkGAPCngfGYfccVQacpUOY/d5+IiIJnhSePWYCA9gGMFoELAGz7tQyPLdjq87W4pyK1eJu5Y4QYvPiIHS9ERERyYPBCRGQFso48JWVp+WA8rTF4ISIiolZkfkQIgxcf8aKGiIhIDgxeiIisgAN2/XaqrgFPL8wyOxmGs8LFOIMXH8ncfUZEJPMDxWSWlV9mdhJckiHA4JgXIiLS1ftrDpidBDpNi06wn3YUBr8SC2PwQkREJJlyFw8DpDMYvPhIhi48IiIio8g8XILBCxEREbXCMS8WIG/8SUREFFoYvBAREZFSGLz4KJi3cBIRESlH3rtGDF6IiIi0JXGrbxEMXoiIiEgpDF58xLtGRETkTWNbwQZDbwxeiIiINPLVpjyzkxASGLwQERFpZHdhBQ4cO2l2MiyPwQsREZGGPuB7pnTH4IWIiEhDJ6rqzE6CJmSeM8XgxUdNA3Y7RLQxNyFEREQhjsELERERtSLznCkGLz6S+e2aREREoYTBi59kvgdIRESkFZnbOwYvRERE1IrNJm/4wuDFR00DdmU+mERERFqR+YXEDF6IiIhIKQxefCRv/ElERBRaGLz4iTeNiIgoFMg8TILBCxERESmFwYuPZB64REREFEoYvPhL3l40IiKikMDgxUfsdyEiolAi8x0HBi9+YscLERGFAg7YJSIiIqXIG7owePFZt+h2+Hz8ELx71yCzk0JERBTSws1OgCo6RITjmotizU4GERFRyGPPCxEREbUi73BdBi9ERETkAse8EBEREWmEwQsREREphcELERERKYXBCxEREbUi8TPqGLwQERGRWhi8EBERkVIYvBAREVErX2/61ewkuMXghYiIiFpJO3Dc7CS4xeCFiIiIlMLghYiIiJTC4IWIiIiUwuCFiIiIlMLghYiIiJTC4IWIiIiUwuCFiIiIlMLghYiIiJSiW/BSUlKCcePGISoqCjExMRg/fjwqKys9/qawsBB33XUX4uLicNZZZ+HKK6/Et99+q1cSiYiISEG6BS/jxo3Djh07kJqaiiVLlmDNmjWYOHGix9/cfffdyMnJweLFi5GVlYU///nPuO2227Blyxa9kklERESK0SV42bVrF1JSUvDhhx8iMTERw4YNw5w5c7BgwQIUFBS4/d369evx17/+FUOGDEGvXr3wzDPPICYmBpmZmXokk4iIiBSkS/CSlpaGmJgYDB482PFZcnIywsLCkJ6e7vZ3Q4cOxZdffomSkhLY7XYsWLAA1dXVuO6669z+pqamBuXl5U5/REREZF26BC+FhYXo0qWL02fh4eHo1KkTCgsL3f7uq6++Ql1dHc4991xERkbiwQcfxMKFC9G7d2+3v5k+fTqio6MdfwkJCZrtBxEREcnHr+BlypQpsNlsHv92794dcGKmTZuG0tJSLFu2DJs2bcKTTz6J2267DVlZWW5/M3XqVJSVlTn+8vLyAt6+rx4Y1hPR7dvqvh0iIiJqzSaEEL4ufPToURw/7vkV2b169cJ//vMfTJ48GSdOnHB8Xl9fj3bt2uHrr7/GLbfc0up3+/fvR+/evZGdnY3LLrvM8XlycjJ69+6Nd99916c0lpeXIzo6GmVlZYiKivJxz/xntwv0enqpbusnIiKS2aEZozVdnz/td7g/K46NjUVsbKzX5ZKSklBaWorMzEwMGjQIALBixQrY7XYkJia6/E1VVRUAICzMuTOoTZs2sNvt/iTTEGFhNrOTQEREFJJ0GfNyySWXYOTIkZgwYQIyMjKwbt06TJo0Cbfffjvi4+MBAPn5+ejbty8yMjIAAH379kXv3r3x4IMPIiMjA/v378frr7+O1NRU3HzzzXokk4iIiBSk23Ne5s2bh759+2L48OEYNWoUhg0bhvfff9/xfV1dHXJychw9Lm3btsXSpUsRGxuLP/7xjxgwYAA+++wzfPrppxg1apReySQiIiLF+HXbyB+dOnXC/Pnz3X7fo0cPtBxuc9FFF/GJukREROQR321ERERESmHwQkREREph8BKEufdeZXYSiIiIQg6DlyD8rm8X7wsRERGRphi8BOlft19udhKIiIhCCoOXIN10+XmOf58dqdvkLSIiIjqNwQsREREphcGLhvjCACIiIv0xeDHAld1jzE4CERGRZTB40cCYK88HADw6/CKX318WH21kcoiIiCyNwYsGXvt/A7BuyvW4+YrzvC9MREREQWHwooGwMBvOi2lvdjKIiIhCAoMXDdk4YpeIiEh3DF6IiIhIKQxeDJDQibeUiIiItMLgxQD3DO1hdhKIiIgsg8GLzq7v2wWR4W2wbsr1mHsf30JNREQULL6MR2fdO3UAAJwX054zkoiIiDTAnhcNuZpsJIQwPB1ERERWxuCFiIiIlMLgRWfsdyEiItIWgxciIiJSCoMXnfGhu0RERNpi8KKhmA4R6NIxErEdIx2f8bYRERGRtjhVWkNtwmxYN+V6AMBF//jR5NQQERFZE3teNNa2TRjatjmTrS1nSg/p0cngFBEREVkLgxeDfXL/VVgw8Wqzk0FERKQsBi86Ey1GvXSICMfVvc41KTVERETqY/BCRERESmHwojMbJ0sTERFpisGLzlreNiIiIqLgMHghIiIipTB40RlfKk1ERKQtBi9ERESkFAYvOmPHCxERkbYYvBAREZFSGLzojBOliYiItMXgRWe8bURERKQtBi9ERESkFAYvOuNUaSIiIm0xeCEiIiKlMHghIiIipTB40cldV1+ANmE2PPTbXmYnhYiIyFLCzU6AVb14cz88+8dL0bYN40MiIiItsWXVEQMXIiIi7bF1JSIiIqUweCEiIiKlMHiRxNjBCY5///7SrogI56EhIiJyhQN2JTF1VF/sLqpAVLtwvH/XIDTYBXr/40ezk0VERCQdXt6b5I4h3QEAb44diC3Tfo+YDhH4/pHf4PPxibDZbAhvE4ZP7rvK5FQSERHJh8GLSV65pR82PZOMW644H+ecFeFymev6dMGdV3c3OGVERERyY/BiEpvNhs5nR3pdrvm7kR6+7kLMGnu5fokiIiJSAIMXyXWIaOP49+PJF+Hcs1330hCRuQZfcI7ZSSAyTL/zokzdPoMXyT3yu964onsMXrzpMkSGt0Fiz3NxWbx2haZd2zAkX9JVs/X5o2M7fcaLx3aMxOPJF+my7pYu7no2br483umzdm3D8Oj1vf1e100t1uPKtRfHov950X6vu7nEnp2C+r0vnh7VV/dtaOl3fWKDXsc7dw4yrUJ/bPhFSH3iWsf/X3Buh6DX2Sv2LMRFtUPbNrag19VSu7Zh6Bbdzumzyb+/GK/fOhAPXqvdK1Um/a43IoJ4WKhN+123jP+MTzR1+zYhmt+YUF95eTmio6NRVlaGqChzI0Oz9Zjyg+Pfh2aMNjEl1vGvZXvx5rI9AJinTex2gV5PLwUALH30GlyqYXBttwvU1NvRvlkPpDu9pv4A++naTM9jU1ZVh/A2NpwV6T34rmuw40RVLbp0bOd12Qc+3Yhlu4oB+Jb+pvP72otj8dn9Q7wur7JQqMs+/OUAXvphFwDr7qM3/rTfnCpN5Ae7tWJ9Teh5dRoWZvMpcAHgCFz0Ft2hrc/Ltm0T5lPgAhiXfpJTXQMLgD90u2308ssvY+jQoejQoQNiYmJ8+o0QAs8++yy6deuG9u3bIzk5GXv37tUriUR+s1hHpSZs7FvXRKBli2XSGuob7GYnQSm6BS+1tbW49dZb8fDDD/v8m1dffRWzZ8/Gu+++i/T0dJx11lkYMWIEqqur9UomkV/YTJBeWLZCWx2DF7/oFry88MILeOKJJ9C/f3+flhdCYNasWXjmmWdw0003YcCAAfjss89QUFCARYsW6ZVMIr80sG+fdMIOFPcu6dY4/mFgQoy5CdFRLW8b+UWa2UYHDx5EYWEhkpOTHZ9FR0cjMTERaWlpbn9XU1OD8vJypz9q9L83XAwAuDvpApNTYh2XxQc308fqzJzKf93pGUOqTllO7OXfLLDbr2p8H9qjw42ZWWemT+67Ck/+/mJ8cPcgs5OiGy1nkYYCaQbsFhYWAgC6dnWettu1a1fHd65Mnz4dL7zwgq5pU9Ujv+uNkf3i0Kvz2WYnxTJG9Y/Dq2MGYEACg5jm5k9IRGV1PbpG+TY4VQ//GnsFFm/Lx+gB3qecy+iBYb0Q0z4Cv+l9rk/LT/9zfzzzh0txtg+znlTXNaqd5YO0PwzohlO1DZbuXdKSXz0vU6ZMgc1m8/i3e/duvdLq0tSpU1FWVub4y8vLM3T7MrPZbOjdpSPCwjigUis2mw23XZWAvnG8Smpu6IWdccNlcaamIbpDW9yV1AOd3LxuQ3YR4WH4S2J3XHDuWT4tb7PZQiJwCRVNdUufuI5mJ0UJfpX8yZMn49577/W4TK9egT1gKC6useIrKipCt27dHJ8XFRXh8ssvd/u7yMhIREZ6f8w+ERERWYNfwUtsbCxiY4N/EqUrPXv2RFxcHJYvX+4IVsrLy5Genu7XjCUiIiKyNt0G7Obm5mLr1q3Izc1FQ0MDtm7diq1bt6KystKxTN++fbFw4UIAjV1mjz/+OF566SUsXrwYWVlZuPvuuxEfH4+bb75Zr2QSERGRYnS7Yfrss8/i008/dfz/FVdcAQBYuXIlrrvuOgBATk4OysrKHMs89dRTOHnyJCZOnIjS0lIMGzYMKSkpaNfOvEGAREREJBe+24iIiIhM50/7Lc1zXoiIiIh8weCFiIiIlMLghYiIiJTC4IWIiIiUwuCFiIiIlMLghYiIiJTC4IWIiIiUwuCFiIiIlGK5V5I2PXOvvLzc5JQQERGRr5rabV+enWu54KWiogIAkJCQYHJKiIiIyF8VFRWIjo72uIzlXg9gt9tRUFCAjh07wmazabru8vJyJCQkIC8vj68e0BHz2RjMZ2Mwn43DvDaGXvkshEBFRQXi4+MRFuZ5VIvlel7CwsJw/vnn67qNqKgonhgGYD4bg/lsDOazcZjXxtAjn731uDThgF0iIiJSCoMXIiIiUgqDFz9ERkbiueeeQ2RkpNlJsTTmszGYz8ZgPhuHeW0MGfLZcgN2iYiIyNrY80JERERKYfBCRERESmHwQkREREph8EJERERKYfDio7fffhs9evRAu3btkJiYiIyMDLOTJLU1a9bgj3/8I+Lj42Gz2bBo0SKn74UQePbZZ9GtWze0b98eycnJ2Lt3r9MyJSUlGDduHKKiohATE4Px48ejsrLSaZnt27fjmmuuQbt27ZCQkIBXX31V712TyvTp03HVVVehY8eO6NKlC26++Wbk5OQ4LVNdXY1HHnkE5557Ls4++2yMGTMGRUVFTsvk5uZi9OjR6NChA7p06YK//e1vqK+vd1pm1apVuPLKKxEZGYnevXvjk08+0Xv3pPHOO+9gwIABjodyJSUl4ccff3R8zzzWx4wZM2Cz2fD44487PmNeB+/555+HzWZz+uvbt6/jeyXyWJBXCxYsEBEREeLjjz8WO3bsEBMmTBAxMTGiqKjI7KRJa+nSpeIf//iH+O677wQAsXDhQqfvZ8yYIaKjo8WiRYvEtm3bxJ/+9CfRs2dPcerUKccyI0eOFAMHDhQbNmwQv/zyi+jdu7e44447HN+XlZWJrl27inHjxons7GzxxRdfiPbt24v33nvPqN003YgRI8TcuXNFdna22Lp1qxg1apTo3r27qKysdCzz0EMPiYSEBLF8+XKxadMmcfXVV4uhQ4c6vq+vrxf9+vUTycnJYsuWLWLp0qWic+fOYurUqY5lDhw4IDp06CCefPJJsXPnTjFnzhzRpk0bkZKSYuj+mmXx4sXihx9+EHv27BE5OTni6aefFm3bthXZ2dlCCOaxHjIyMkSPHj3EgAEDxGOPPeb4nHkdvOeee05cdtll4siRI46/o0ePOr5XIY8ZvPhgyJAh4pFHHnH8f0NDg4iPjxfTp083MVXqaBm82O12ERcXJ1577TXHZ6WlpSIyMlJ88cUXQgghdu7cKQCIjRs3Opb58ccfhc1mE/n5+UIIIf7973+Lc845R9TU1DiW+fvf/y769Omj8x7Jq7i4WAAQq1evFkI05mvbtm3F119/7Vhm165dAoBIS0sTQjQGmmFhYaKwsNCxzDvvvCOioqIcefvUU0+Jyy67zGlbY8eOFSNGjNB7l6R1zjnniA8//JB5rIOKigpx0UUXidTUVPHb3/7WEbwwr7Xx3HPPiYEDB7r8TpU85m0jL2pra5GZmYnk5GTHZ2FhYUhOTkZaWpqJKVPXwYMHUVhY6JSn0dHRSExMdORpWloaYmJiMHjwYMcyycnJCAsLQ3p6umOZa6+9FhEREY5lRowYgZycHJw4ccKgvZFLWVkZAKBTp04AgMzMTNTV1Tnldd++fdG9e3envO7fvz+6du3qWGbEiBEoLy/Hjh07HMs0X0fTMqF4DjQ0NGDBggU4efIkkpKSmMc6eOSRRzB69OhW+cG81s7evXsRHx+PXr16Ydy4ccjNzQWgTh4zePHi2LFjaGhocDpIANC1a1cUFhaalCq1NeWbpzwtLCxEly5dnL4PDw9Hp06dnJZxtY7m2wgldrsdjz/+OH7zm9+gX79+ABrzISIiAjExMU7Ltsxrb/nobpny8nKcOnVKj92RTlZWFs4++2xERkbioYcewsKFC3HppZcyjzW2YMECbN68GdOnT2/1HfNaG4mJifjkk0+QkpKCd955BwcPHsQ111yDiooKZfLYcm+VJgpVjzzyCLKzs7F27Vqzk2JJffr0wdatW1FWVoZvvvkG99xzD1avXm12siwlLy8Pjz32GFJTU9GuXTuzk2NZN954o+PfAwYMQGJiIi644AJ89dVXaN++vYkp8x17Xrzo3Lkz2rRp02qkdVFREeLi4kxKldqa8s1TnsbFxaG4uNjp+/r6epSUlDgt42odzbcRKiZNmoQlS5Zg5cqVOP/88x2fx8XFoba2FqWlpU7Lt8xrb/nobpmoqChlKrtgRUREoHfv3hg0aBCmT5+OgQMH4l//+hfzWEOZmZkoLi7GlVdeifDwcISHh2P16tWYPXs2wsPD0bVrV+a1DmJiYnDxxRdj3759ypRnBi9eREREYNCgQVi+fLnjM7vdjuXLlyMpKcnElKmrZ8+eiIuLc8rT8vJypKenO/I0KSkJpaWlyMzMdCyzYsUK2O12JCYmOpZZs2YN6urqHMukpqaiT58+OOeccwzaG3MJITBp0iQsXLgQK1asQM+ePZ2+HzRoENq2beuU1zk5OcjNzXXK66ysLKdgMTU1FVFRUbj00ksdyzRfR9MyoXwO2O121NTUMI81NHz4cGRlZWHr1q2Ov8GDB2PcuHGOfzOvtVdZWYn9+/ejW7du6pRnTYb9WtyCBQtEZGSk+OSTT8TOnTvFxIkTRUxMjNNIa3JWUVEhtmzZIrZs2SIAiDfeeENs2bJFHD58WAjROFU6JiZGfP/992L79u3ipptucjlV+oorrhDp6eli7dq14qKLLnKaKl1aWiq6du0q7rrrLpGdnS0WLFggOnToEFJTpR9++GERHR0tVq1a5TTtsaqqyrHMQw89JLp37y5WrFghNm3aJJKSkkRSUpLj+6ZpjzfccIPYunWrSElJEbGxsS6nPf7tb38Tu3btEm+//XZITS2dMmWKWL16tTh48KDYvn27mDJlirDZbOLnn38WQjCP9dR8tpEQzGstTJ48WaxatUocPHhQrFu3TiQnJ4vOnTuL4uJiIYQaeczgxUdz5swR3bt3FxEREWLIkCFiw4YNZidJaitXrhQAWv3dc889QojG6dLTpk0TXbt2FZGRkWL48OEiJyfHaR3Hjx8Xd9xxhzj77LNFVFSUuO+++0RFRYXTMtu2bRPDhg0TkZGR4rzzzhMzZswwahel4CqPAYi5c+c6ljl16pT4n//5H3HOOeeIDh06iFtuuUUcOXLEaT2HDh0SN954o2jfvr3o3LmzmDx5sqirq3NaZuXKleLyyy8XERERolevXk7bsLr7779fXHDBBSIiIkLExsaK4cOHOwIXIZjHemoZvDCvgzd27FjRrVs3ERERIc477zwxduxYsW/fPsf3KuSxTQghtOnDISIiItIfx7wQERGRUhi8EBERkVIYvBAREZFSGLwQERGRUhi8EBERkVIYvBAREZFSGLwQERGRUhi8EBERkVIYvBAREZFSGLwQERGRUhi8EBERkVIYvBAREZFS/j97UVFEWYwofwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episode_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DQN Agent\n",
    "class DQNAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_size,\n",
    "        action_size,\n",
    "        device,\n",
    "        gamma=0.99,\n",
    "        lr=0.001,\n",
    "        batch_size=64,\n",
    "        buffer_size=10000,\n",
    "        target_update=10,\n",
    "    ):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.target_update = target_update\n",
    "        self.device = device\n",
    "\n",
    "        # Initialize main and target networks\n",
    "        self.policy_net = QNetwork(state_size, action_size).to(device)\n",
    "        self.target_net = QNetwork(state_size, action_size).to(device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        self.target_net.eval()\n",
    "\n",
    "        # Set up optimizer and replay memory\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=lr)\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.steps_done = 0\n",
    "\n",
    "    def select_action(self, state, epsilon):\n",
    "        if random.random() < epsilon:\n",
    "            return random.choice(range(self.action_size))\n",
    "        with torch.no_grad():\n",
    "            state = torch.FloatTensor(state).to(self.device)\n",
    "            return torch.argmax(self.policy_net(state)).item()\n",
    "\n",
    "    def store_transition(self, transition):\n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample_batch(self):\n",
    "        return random.sample(self.memory, self.batch_size)\n",
    "\n",
    "    def update_q_values(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        batch = self.sample_batch()\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.LongTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).to(self.device)\n",
    "\n",
    "        # Calculate Q(s, a) using policy network\n",
    "        current_q_values = (\n",
    "            self.policy_net(states).gather(1, actions.unsqueeze(1)).squeeze()\n",
    "        )\n",
    "\n",
    "        # Calculate target Q-values\n",
    "        with torch.no_grad():\n",
    "            max_next_q_values = self.target_net(next_states).max(1)[0]\n",
    "            target_q_values = rewards + (1 - dones) * self.gamma * max_next_q_values\n",
    "\n",
    "        # Compute loss\n",
    "        loss = nn.functional.mse_loss(current_q_values, target_q_values)\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Update target network every target_update steps\n",
    "        if self.steps_done % self.target_update == 0:\n",
    "            self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        env,\n",
    "        num_episodes,\n",
    "        max_iters,\n",
    "        epsilon_start=1.0,\n",
    "        epsilon_end=0.1,\n",
    "        epsilon_decay=0.995,\n",
    "    ):\n",
    "        epsilon = epsilon_start\n",
    "        returns = []\n",
    "\n",
    "        with tqdm(total=num_episodes, desc=\"Training DQN\") as pbar:\n",
    "            for episode in range(num_episodes):           \n",
    "                state = env.reset()\n",
    "                done = False\n",
    "                episode_return = 0\n",
    "                t = 0\n",
    "                while not done and t < max_iters:\n",
    "                    action = self.select_action(state, epsilon)\n",
    "                    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "                    # Store transition in memory\n",
    "                    self.store_transition((state, action, reward/max_iters, next_state, done))\n",
    "\n",
    "                    # Update Q values\n",
    "                    self.update_q_values()\n",
    "\n",
    "                    # Move to the next state\n",
    "                    state = next_state\n",
    "                    episode_return += reward\n",
    "                    self.steps_done += 1\n",
    "                    t += 1\n",
    "\n",
    "                # Decay epsilon\n",
    "                epsilon = max(epsilon_end, epsilon * epsilon_decay)\n",
    "                returns.append(episode_return)\n",
    "                # tqdm.write(f\"Episode {episode + 1}: Return = {episode_return:.2f}\")\n",
    "                pbar.set_postfix(Return=episode_return)\n",
    "                pbar.update(1)\n",
    "\n",
    "        return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "agent = DQNAgent(state_space, state_space, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SEUFSEnvironment(state_size=state_space, data=X_train, online=False)\n",
    "episode_returns = agent.train(env=env, num_episodes=5000, max_iters=state_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(episode_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inno-em",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
