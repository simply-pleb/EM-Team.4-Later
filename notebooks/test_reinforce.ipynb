{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.envs import RLFSEnvSparse\n",
    "from src.rl import REINFORCE\n",
    "from src.errors import sammon_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INF_LOOP_CNT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_frames(train_path, test_path):\n",
    "    data_train = pd.read_csv(train_path, sep=\",\")\n",
    "    data_test = pd.read_csv(test_path, sep=\",\")\n",
    "\n",
    "    return data_train, data_test\n",
    "\n",
    "\n",
    "def get_data_train_test(data_train, data_test):\n",
    "    X_train = data_train.drop(columns=[\"repository\"], inplace=False)\n",
    "    X_train = X_train.to_numpy()\n",
    "\n",
    "    X_test = data_test.drop(columns=[\"repository\"], inplace=False)\n",
    "    X_test = X_test.to_numpy()\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "def powers_of_two_less_than(n):\n",
    "    max_exponent = int(np.log2(n))  # Find the largest exponent such that 2^k < N\n",
    "    return 2 ** np.arange(max_exponent+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_reinforce_agent(X_train, agent, device, make_plots=False):\n",
    "    state_space = X_train.shape[1]\n",
    "    action_space = X_train.shape[1]\n",
    "    for i, num_features in enumerate(powers_of_two_less_than(state_space//2)):\n",
    "            env = RLFSEnvSparse(\n",
    "                state_size=state_space, data=X_train, max_features=num_features\n",
    "            )\n",
    "            print(f\"Iteration {i}, Number of features {num_features}\")\n",
    "            episode_returns = agent.train(\n",
    "                env=env,\n",
    "                num_episodes=500 + 300 // (i+1),\n",
    "                max_steps=num_features,\n",
    "            )\n",
    "            # torch.save(agent.policy.state_dict(), \"models/REINFORCE/policy_weights.pth\")\n",
    "            if make_plots:\n",
    "                plt.plot(episode_returns)\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(X_test, data_test, agent, verbose=True):\n",
    "    state_space = X_test.shape[1]\n",
    "    action_space = X_test.shape[1]\n",
    "    env = RLFSEnvSparse(state_size=state_space, data=X_test, max_features=state_space)\n",
    "    errors = []\n",
    "    num_ftrs = []\n",
    "    selected_features = []\n",
    "    if verbose:\n",
    "        print(\"waiting...\")\n",
    "    for n in range(0, state_space+1):\n",
    "        state = env.reset()\n",
    "        # errors.append(sammon_error(X_test, state))\n",
    "        state_cnt = 0  # int(np.sum(state))\n",
    "        done = False\n",
    "        # if verbose:\n",
    "        #     print(f\"n={n}\")\n",
    "        inf_loop_cnt = INF_LOOP_CNT\n",
    "        action_sequence = []\n",
    "        while state_cnt < n and not done:\n",
    "            if inf_loop_cnt > 0:\n",
    "                action, action_prob = agent.select_action_deterministic(state)\n",
    "            else:\n",
    "                # print(\"+\")\n",
    "                action, action_prob = agent.select_action(state)\n",
    "                # print(np.exp(action_prob.detach().numpy()))\n",
    "\n",
    "            next_state, _, done, _ = env.step(action)\n",
    "            action_sequence.append(action)\n",
    "\n",
    "            if int(np.sum(next_state)) > state_cnt:\n",
    "                # print(state_cnt)\n",
    "                inf_loop_cnt = INF_LOOP_CNT\n",
    "                state_cnt = int(np.sum(next_state))\n",
    "            else:\n",
    "                inf_loop_cnt -= 1\n",
    "\n",
    "            state = next_state\n",
    "        # print(np.sum(state))\n",
    "        error = sammon_error(X_test, state)\n",
    "        errors.append(error)\n",
    "        num_ftrs.append(n)\n",
    "        selected_features.append(\n",
    "            [data_test.drop(columns=[\"repository\"]).columns[action] for action in action_sequence]\n",
    "        )\n",
    "\n",
    "    return errors, num_ftrs, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_class = \"../data/data_class_train.csv\"\n",
    "test_path_class = \"../data/data_class.csv\"\n",
    "train_path_method = \"../data/data_method_train.csv\"\n",
    "test_path_method = \"../data/data_method.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_method, data_test_method = get_data_frames(train_path_method, test_path_method)\n",
    "X_train_method, X_test_method = get_data_train_test(data_train_method, data_test_method)\n",
    "state_space_method = X_train_method.shape[1]\n",
    "action_space_method = X_train_method.shape[1]\n",
    "\n",
    "data_train_class, data_test_class = get_data_frames(train_path_class, test_path_class)\n",
    "X_train_class, X_test_class = get_data_train_test(data_train_class, data_test_class)\n",
    "state_space_class = X_train_class.shape[1]\n",
    "action_space_class = X_train_class.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_method.shape, data_test_method.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_class.shape, data_test_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "agent = REINFORCE.REINFORCEAgent(state_space_method, action_space_method, gamma=1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_test(X_train, X_test, data_test, agent, device):\n",
    "    train_reinforce_agent(X_train, agent, device)\n",
    "    return test_agent(X_test, data_test, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_method = REINFORCE.REINFORCEAgent(\n",
    "    state_space_method, action_space_method, gamma=1, lr=0.0001\n",
    ")\n",
    "errors, num_ftrs, selected_features = run_train_test(\n",
    "    X_train=X_train_method,\n",
    "    X_test=X_test_method,\n",
    "    data_test=data_test_method,\n",
    "    agent=agent_method,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_ = ['']\n",
    "selected_features_.extend(selected_features[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 7.5))\n",
    "plt.plot(num_ftrs, errors, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Sequentially Selected Metrics')\n",
    "plt.ylabel('Sammon Error')\n",
    "# plt.title('Sammon Error vs Number of Features')\n",
    "plt.xticks(num_ftrs, selected_features_, rotation=45, ha='right')  # Map indices to feature names\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_class = REINFORCE.REINFORCEAgent(\n",
    "    state_space_class, action_space_class, gamma=1, lr=0.0001\n",
    ")\n",
    "errors, num_ftrs, selected_features = run_train_test(\n",
    "    X_train=X_train_class,\n",
    "    X_test=X_test_class,\n",
    "    data_test=data_test_class,\n",
    "    agent=agent_class,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_ = ['']\n",
    "selected_features_.extend(selected_features[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selected_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 7.5))\n",
    "plt.plot(num_ftrs, errors, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Sequentially Selected Metrics')\n",
    "plt.ylabel('Sammon Error')\n",
    "# plt.title('Sammon Error vs Number of Features')\n",
    "plt.xticks(num_ftrs, selected_features_, rotation=45, ha='right')  # Map indices to feature names\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stability(X_train, X_test, data_test, num_iters=10):\n",
    "    state_space = X_train.shape[1]\n",
    "    action_space = X_train.shape[1]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    all_errors = []\n",
    "    all_num_ftrs = []\n",
    "    all_selected_features = []\n",
    "    for i in range(num_iters):\n",
    "        agent = REINFORCE.REINFORCEAgent(state_space, action_space, gamma=1, lr=0.0001)\n",
    "        errors, num_ftrs, selected_features = run_train_test(\n",
    "            X_train, X_test, data_test, agent, device\n",
    "        )\n",
    "        all_errors.append(errors)\n",
    "        all_num_ftrs.append(num_ftrs)\n",
    "        all_selected_features.append(selected_features)\n",
    "\n",
    "    return all_errors, all_num_ftrs, all_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors, all_num_ftrs, all_selected_features = test_stability(X_train_class, X_test_class, data_test_class, num_iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_errors = np.min(all_errors, axis=0)\n",
    "max_errors = np.max(all_errors, axis=0)\n",
    "avg_errors = np.mean(all_errors, axis=0)\n",
    "min_errors, max_errors, avg_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reinforce_class = pd.DataFrame({\n",
    "    \"number_of_features\": all_num_ftrs[0],\n",
    "    \"min_error\": min_errors,\n",
    "    \"max_error\": max_errors,\n",
    "    \"avg_error\": avg_errors\n",
    "})\n",
    "df_reinforce_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reinforce_class.to_csv(\"../data/results/REINFORCE_class.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 7.5))\n",
    "plt.plot(all_num_ftrs[0], min_errors, marker='o', label='Minimum Error')\n",
    "plt.plot(all_num_ftrs[0], max_errors, marker='o', label='Maximum Error')\n",
    "plt.plot(all_num_ftrs[0], avg_errors, marker='o', label='Average Error')\n",
    "\n",
    "# Add plot details\n",
    "plt.xlabel('Number of Metrics')\n",
    "plt.ylabel('Sammon Error')\n",
    "# plt.title('Model Stability across Retrainings')\n",
    "plt.xticks(all_num_ftrs[0])  # Ensure x-axis ticks are integers from all_num_ftrs\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors_m, all_num_ftrs_m, all_selected_features_m = test_stability(X_train_method, X_test_method, data_test_method, num_iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_selected_features[0][-1])\n",
    "print([float(error) for error in all_errors[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_selected_features_m[0][-1])\n",
    "print([float(error) for error in all_errors_m[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_errors = np.min(all_errors_m, axis=0)\n",
    "max_errors = np.max(all_errors_m, axis=0)\n",
    "avg_errors = np.mean(all_errors_m, axis=0)\n",
    "min_errors, max_errors, avg_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reinforce_method = pd.DataFrame({\n",
    "    \"number_of_features\": all_num_ftrs_m[0],\n",
    "    \"min_error\": min_errors,\n",
    "    \"max_error\": max_errors,\n",
    "    \"avg_error\": avg_errors\n",
    "})\n",
    "df_reinforce_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reinforce_method.to_csv(\"../data/results/REINFORCE_method.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 7.5))\n",
    "plt.plot(all_num_ftrs_m[0], min_errors, marker='o', label='Minimum Error')\n",
    "plt.plot(all_num_ftrs_m[0], max_errors, marker='o', label='Maximum Error')\n",
    "plt.plot(all_num_ftrs_m[0], avg_errors, marker='o', label='Average Error')\n",
    "\n",
    "# Add plot details\n",
    "plt.xlabel('Number of Metrics')\n",
    "plt.ylabel('Sammon Error')\n",
    "# plt.title('Model Stability across Retrainings')\n",
    "plt.xticks(all_num_ftrs_m[0])  # Ensure x-axis ticks are integers from all_num_ftrs\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inno-em",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
